# [Xception] Xception: Deep Learning With Depthwise Separable Convolutions
Xceptionì€ Inception ê³„ì—´ì˜ ëª¨ë“ˆì„ ë‹¤ì‹œ í•´ì„í•˜ëŠ” ê²ƒì—ì„œ ì¶œë°œí•œë‹¤. ë…¼ë¬¸ì€ Inception ëª¨ë“ˆì´ **ì •ê·œ convolution**ê³¼ **Depthwise Separable Convolution** ì‚¬ì´ì˜ ì—°ì†ì²´(ì •í™•íˆëŠ” ë¶„í•  ìˆ˜ë¡œ ë§¤ê°œë˜ëŠ” ì´ì‚° ìŠ¤í™íŠ¸ëŸ¼) ìœ„ì— ë†“ì—¬ ìˆìœ¼ë©°, Depthwise Separable Convolutionì€ Inception ëª¨ë“ˆì„ ê·¹ë‹¨ìœ¼ë¡œ ë°€ì–´ë¶™ì¸ í˜•íƒœë¡œ ì´í•´í•  ìˆ˜ ìˆë‹¤ê³  ì£¼ì¥í•œë‹¤. ì´ ê´€ì ì„ ê¸°ë°˜ìœ¼ë¡œ, Inception ëª¨ë“ˆì„ **Depthwise Separable Convolutionìœ¼ë¡œ ì „ë©´ ì¹˜í™˜**í•œ ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆí•˜ë©°, ì´ë¥¼ *Extreme Inception*ì´ë¼ëŠ” ì˜ë¯¸ì˜ **Xception**ìœ¼ë¡œ ëª…ëª…í•œë‹¤.

ë…¼ë¬¸ì˜ í•µì‹¬ ë©”ì‹œì§€ëŠ” ì„±ëŠ¥ í–¥ìƒì´ ë‹¨ìˆœí•œ íŒŒë¼ë¯¸í„° ì¦ê°€ê°€ ì•„ë‹ˆë¼ **íŒŒë¼ë¯¸í„° ì‚¬ìš© ë°©ì‹ì˜ íš¨ìœ¨**ì—ì„œ ê¸°ì¸í•œë‹¤ëŠ” ì ì´ë‹¤. ImageNetì—ì„œëŠ” Inception V3 ëŒ€ë¹„ ì†Œí­ ê°œì„ ì„, í›¨ì”¬ í° ë‚´ë¶€ ë°ì´í„°ì…‹(JFT)ì—ì„œëŠ” í° ê°œì„ ì„ ë³´ê³ í•œë‹¤. ë˜í•œ Residual Connectionì˜ ì¤‘ìš”ì„±, Depthwiseâ€“Pointwise ì‚¬ì´ì˜ ì¤‘ê°„ activation ìœ ë¬´ê°€ í•™ìŠµì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë³„ë„ ì‹¤í—˜ìœ¼ë¡œ ë¶„í•´í•´ ë…¼ì¦í•œë‹¤.

(Fig. 1: Inception V3ì—ì„œ ì‚¬ìš©ë˜ëŠ” Canonical Inception Module)  

## 1ï¸âƒ£ Introduction

### ğŸ”¹ ë¬¸ì œì˜ì‹: Convolutionì´ ë™ì‹œì— ë§¡ëŠ” ë‘ ì¢…ë¥˜ì˜ ìƒê´€ê´€ê³„
ë…¼ë¬¸ì€ convolution layerê°€ ì‚¬ì‹¤ìƒ 3ì°¨ì› ê³µê°„ì—ì„œ í•„í„°ë¥¼ í•™ìŠµí•œë‹¤ê³  ë³¸ë‹¤. ì—¬ê¸°ì„œ 3ì°¨ì›ì€ ê³µê°„ ì¶•(ê°€ë¡œÂ·ì„¸ë¡œ)ê³¼ ì±„ë„ ì¶•ì„ í¬í•¨í•œë‹¤. ì¦‰, ë‹¨ì¼ convolution kernelì€

- **Cross-Channel Correlation**(ì±„ë„ ê°„ ìƒê´€ê´€ê³„)
- **Spatial Correlation**(ê³µê°„ì  ìƒê´€ê´€ê³„)

ì„ ë™ì‹œì— ëª¨ë¸ë§í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•œë‹¤. ì´ ë™ì‹œ ëª¨ë¸ë§ì´ ê³¼ì—° ê°€ì¥ íš¨ìœ¨ì ì¸ê°€ê°€ Inception ë° Xceptionì˜ ë¬¸ì œì˜ì‹ìœ¼ë¡œ ì—°ê²°ëœë‹¤.

#### Convolution Kernel Parameterization
ì´ ë¬¸ì œì˜ì‹ì„ í…ì„œ ê´€ì ìœ¼ë¡œ ë” êµ¬ì²´í™”í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ì¼ë°˜ì ì¸ 2D convolutionì—ì„œ í•˜ë‚˜ì˜ ì»¤ë„ì€ ê³µê°„ í¬ê¸° $k\times k$ì™€ ì±„ë„ ì¶•ì„ í•¨ê»˜ ê°–ëŠ”ë‹¤. ì…ë ¥ ì±„ë„ ìˆ˜ë¥¼ $C_{in}$, ì¶œë ¥ ì±„ë„ ìˆ˜ë¥¼ $C_{out}$ì´ë¼ í•˜ë©´, íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ëŒ€ëµ

$$
k^2\cdot C_{in}\cdot C_{out}
$$

ìœ¼ë¡œ ì¦ê°€í•œë‹¤. ì´ êµ¬ì¡°ëŠ” í•œ ë²ˆì˜ convolutionì´

- ì±„ë„ ì¶•ì—ì„œ ì–´ë–¤ ì…ë ¥ ì±„ë„ ì¡°í•©ì„ ë§Œë“¤ì§€  
- ê³µê°„ ì¶•ì—ì„œ ì–´ë–¤ íŒ¨í„´ì„ ê²€ì¶œí• ì§€  

ë¥¼ í•¨ê»˜ ê²°ì •í•´ì•¼ í•¨ì„ ì˜ë¯¸í•œë‹¤. ë…¼ë¬¸ì´ ë§í•˜ëŠ” ë¶„í•´ ê°€ëŠ¥ì„±ì€ ê²°êµ­ ì´ ê²°í•©ëœ íŒŒë¼ë¯¸í„°í™”ê°€ í•­ìƒ ìµœì„ ì€ ì•„ë‹ ìˆ˜ ìˆë‹¤ëŠ” ì£¼ì¥ê³¼ ì—°ê²°ëœë‹¤.

#### ì„¤ê³„ ê´€ì  ìš”ì•½: ê²°í•© í•™ìŠµê³¼ ë¶„í•´ í•™ìŠµì˜ ëŒ€ë¹„
ì •ê·œ convolutionì€ ì±„ë„ í˜¼í•©ê³¼ ê³µê°„ ë³€í™˜ì„ í•œ ë²ˆì— í•™ìŠµí•˜ëŠ” ë°©ì‹ì´ê³ , Inception ë° Xceptionì€ ì´ë¥¼ ë¶„í•´í•´ í•™ìŠµ ë¶€ë‹´ì„ ì¤„ì´ëŠ” ë°©í–¥ì„ íƒí•œë‹¤. ì´í›„ ì„¹ì…˜ì—ì„œ ë…¼ë¬¸ì€ Inceptionì´ ìˆ˜í–‰í•œ ë¶„í•´ê°€ ì–´ëŠ ì •ë„ ìˆ˜ì¤€ì¸ì§€, ê·¸ë¦¬ê³  ê·¸ ë¶„í•´ë¥¼ ê·¹ë‹¨ìœ¼ë¡œ ë°€ì–´ë¶™ì´ë©´ ë¬´ì—‡ì´ ë˜ëŠ”ì§€ë¥¼ Fig. 2â€“4ë¥¼ í†µí•´ ì „ê°œí•œë‹¤.

### ğŸ”¸ Inception Hypothesis: ì±„ë„ ìƒê´€ê´€ê³„ì™€ ê³µê°„ ìƒê´€ê´€ê³„ì˜ ë¶„í•´
ë…¼ë¬¸ì€ Inception ëª¨ë“ˆì˜ ê¸°ë³¸ ê°€ì„¤ì„ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•œë‹¤. Cross-channel correlationê³¼ spatial correlationì€ ì¶©ë¶„íˆ ë¶„ë¦¬ ê°€ëŠ¥í•˜ë©°, ë”°ë¼ì„œ ë‘˜ì„ í•˜ë‚˜ì˜ convolutionì—ì„œ í•¨ê»˜ ì²˜ë¦¬í•˜ê¸°ë³´ë‹¤ **ë¶„í•´ëœ ì—°ì‚°ì˜ ì—°ì‡„**ë¡œ ì²˜ë¦¬í•˜ëŠ” í¸ì´ ë” íš¨ìœ¨ì ì¼ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤.

ë…¼ë¬¸ì´ ì œì‹œí•˜ëŠ” ì „í˜•ì  íë¦„ì€ ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¡œ ì´í•´í•  ìˆ˜ ìˆë‹¤.

1. 1Ã—1 convolutionìœ¼ë¡œ ì±„ë„ ë°©í–¥ì˜ í˜¼í•©ì„ ìˆ˜í–‰í•˜ì—¬ ì…ë ¥ì„ ë” ì‘ì€ ì±„ë„ ê³µê°„ë“¤ë¡œ ì‚¬ìƒí•œë‹¤.  
2. ê° ì±„ë„ ê³µê°„ì—ì„œ 3Ã—3 ë˜ëŠ” 5Ã—5 ê°™ì€ ê³µê°„ convolutionì„ ìˆ˜í–‰í•œë‹¤.  

ì¦‰, ì±„ë„ í˜¼í•©ì„ ë¨¼ì € ìˆ˜í–‰í•˜ê³  ê·¸ ê²°ê³¼ ìœ„ì—ì„œ ê³µê°„ ë³€í™˜ì„ ìˆ˜í–‰í•œë‹¤ëŠ” ì ì—ì„œ, Inceptionì€ ë‹¨ì¼ convolutionì´ ìˆ˜í–‰í•˜ë˜ ì¼ì„ ë¶€ë¶„ì ìœ¼ë¡œ ë¶„í•´í•œë‹¤.

(Fig. 2: Pooling Towerê°€ ì œì™¸ëœ Simplified Inception Module)  
(Fig. 3: Simplified Inception Moduleì˜ Strictly Equivalent Reformulation)  

#### Canonical Inception Moduleê³¼ Simplified Inception Moduleì˜ ì—­í•  ë¶„ë¦¬
ë…¼ë¬¸ì€ Fig. 1ì—ì„œ Inception V3ì˜ canonical moduleì„ ë³´ì—¬ì£¼ì§€ë§Œ, ì„¤ê³„ í•´ì„ì„ ìœ„í•´ Fig. 2ì—ì„œ ë‹¨ìˆœí™”ëœ Inception moduleì„ ì‚¬ìš©í•œë‹¤. ì´ ë‹¨ìˆœí™”ëŠ” í•µì‹¬ ë…¼ì ì„ ë¶„ë¦¬í•˜ê¸° ìœ„í•œ ì¥ì¹˜ë¡œ ì´í•´í•  ìˆ˜ ìˆë‹¤.

1. canonical moduleì˜ êµ¬í˜„ ë””í…Œì¼ì„ ì œê±°í•˜ê³ , ì±„ë„ í˜¼í•©ê³¼ ê³µê°„ ë³€í™˜ì˜ ë¶„í•´ë¼ëŠ” í•µì‹¬ë§Œ ë‚¨ê¸´ë‹¤.  
2. ë¶„í•´ë¥¼ ì±„ë„ ë¶„í• ì˜ ê´€ì ìœ¼ë¡œ ì¬í‘œí˜„í•˜ê¸° ìœ„í•´, ë™ì¼ í¬ê¸°ì˜ ê³µê°„ convolutionë§Œ ë‚¨ê¸´ë‹¤.  

ì´ë ‡ê²Œ ë‹¨ìˆœí™”ëœ êµ¬ì¡°ì—ì„œ, ì±„ë„ì„ ëª‡ ê°œì˜ segmentë¡œ ë‚˜ëˆ„ì–´ ê³µê°„ convolutionì„ ìˆ˜í–‰í•˜ëŠ”ì§€ì˜ ê´€ì ì´ ë“±ì¥í•˜ê³ , ì´ëŠ” depthwise separable convolutionìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§„ë‹¤.

### ğŸ”¹ ì§ˆë¬¸ì˜ í™•ì¥: ë¶„í•´ë¥¼ ë” ê·¹ë‹¨ìœ¼ë¡œ ë°€ì–´ë¶™ì´ë©´ ë¬´ì—‡ì´ ë˜ëŠ”ê°€
ë…¼ë¬¸ì€ Fig. 2ì˜ ë‹¨ìˆœí™”ëœ Inception ëª¨ë“ˆì„ Fig. 3ì²˜ëŸ¼ ë‹¤ì‹œ ì“¸ ìˆ˜ ìˆìŒì„ ì§€ì í•œë‹¤. ì—¬ê¸°ì„œ í•µì‹¬ì€ 1Ã—1 convolution ë’¤ì˜ ê³µê°„ convolutionì´ **ì¶œë ¥ ì±„ë„ì„ ëª‡ ê°œì˜ segmentë¡œ ë‚˜ëˆ„ì–´** ê° segmentì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ ì ìš©ë˜ëŠ” ê²ƒìœ¼ë¡œ ì¬í•´ì„ë  ìˆ˜ ìˆë‹¤ëŠ” ì ì´ë‹¤.

ì´ë•Œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ìŒ ì§ˆë¬¸ì´ ìƒê¸´ë‹¤.

1. segmentì˜ ìˆ˜ë¥¼ ëŠ˜ë¦¬ë©´ ì–´ë–¤ ì¼ì´ ìƒê¸°ëŠ”ê°€  
2. segmentì˜ í¬ê¸°ë¥¼ ì¤„ì—¬ 1ê°œ ì±„ë„ ë‹¨ìœ„ê¹Œì§€ ë¶„í•´í•˜ë©´ ë¬´ì—‡ì´ ë˜ëŠ”ê°€  

ë…¼ë¬¸ì€ ì´ ì§ˆë¬¸ì„ í†µí•´ **ì •ê·œ convolutionê³¼ depthwise separable convolutionì´ í•˜ë‚˜ì˜ ì—°ì†ì„  ìœ„ì— ë†“ì¸ë‹¤**ëŠ” ê´€ì ì„ ì œì‹œí•œë‹¤.

(Fig. 4: Output Channelë§ˆë‹¤ Spatial Convolutionì„ ë‘ëŠ” Extreme Inception í˜•íƒœ)  

#### Segmented Spatial Convolutionê³¼ Grouped Convolutionì˜ ëŒ€ì‘
Fig. 3ì˜ ì¬í‘œí˜„ì€ êµ¬í˜„ ê´€ì ì—ì„œ ë³´ë©´ grouped convolutionê³¼ ë§¤ìš° ìœ ì‚¬í•œ í˜•íƒœë¡œ í•´ì„ë  ìˆ˜ ìˆë‹¤. ì±„ë„ì„ ì—¬ëŸ¬ segmentë¡œ ë‚˜ëˆ„ì–´ ê° segmentì— ëŒ€í•´ ë…ë¦½ì ì¸ ê³µê°„ convolutionì„ ì ìš©í•œë‹¤ëŠ” ê²ƒì€, convolutionì˜ `groups`ë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” ë°©í–¥ê³¼ ê°™ì€ í˜•íƒœì˜ ë¶„í•´ë¥¼ ì˜ë¯¸í•œë‹¤.

- segment ìˆ˜ê°€ ì‘ìœ¼ë©´, ê° segmentê°€ ë‹´ë‹¹í•˜ëŠ” ì±„ë„ í­ì´ ë„“ì–´ì ¸ ì •ê·œ convolutionê³¼ ìœ ì‚¬í•´ì§„ë‹¤.  
- segment ìˆ˜ê°€ ì»¤ì§€ë©´, ê° segmentê°€ ë‹´ë‹¹í•˜ëŠ” ì±„ë„ í­ì´ ì¢ì•„ì ¸ depthwiseì— ê°€ê¹Œì›Œì§„ë‹¤.  

ë…¼ë¬¸ì€ ì´ êµ¬ì¡°ê°€ ì•„ì§ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ë‹¤ê³  ë§í•˜ë©°, Xceptionì˜ ë‹¤ìŒ ë‹¨ê³„ë¡œì„œ ì¤‘ê°„ ì§€ì  íƒìƒ‰ì„ Future Directionsë¡œ ë‚¨ê¸´ë‹¤.

#### Depthwise Separable Convolutionì˜ ì—°ì‚° ë¹„ìš© ì§ê´€
ì •ê·œ convolutionê³¼ depthwise separable convolutionì„ íŒŒë¼ë¯¸í„° ìˆ˜ ê´€ì ì—ì„œ ë¹„êµí•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì§ê´€ì„ ì–»ì„ ìˆ˜ ìˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ depthwise separableì€

1. depthwise ë‹¨ê³„: $k^2\cdot C_{in}$  
2. pointwise ë‹¨ê³„: $C_{in}\cdot C_{out}$  

ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°–ëŠ”ë‹¤. ë”°ë¼ì„œ í•©ì€ $k^2\cdot C_{in} + C_{in}\cdot C_{out}$ê°€ ëœë‹¤. $k^2\cdot C_{in}\cdot C_{out}$ì— ë¹„í•´ í›¨ì”¬ ì‘ì•„ì§ˆ ìˆ˜ ìˆìœ¼ë©°, ë…¼ë¬¸ì´ ë§í•˜ëŠ” íš¨ìœ¨ì  íŒŒë¼ë¯¸í„° ì‚¬ìš©ì´ë¼ëŠ” í‘œí˜„ì„ êµ¬ì¡°ì ìœ¼ë¡œ ë’·ë°›ì¹¨í•œë‹¤.

#### Depthwise Separable Convolution Forward Pseudocode
ë…¼ë¬¸ ì •ì˜ë¥¼ êµ¬í˜„ ì ˆì°¨ë¡œ ì •ë¦¬í•˜ë©´ ë‹¤ìŒ ì˜ì‚¬ì½”ë“œë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.

```text
Algorithm: Depthwise Separable Convolution Forward
Inputs:
  - Input feature map X (N x Cin x H x W)
  - Depthwise kernels Kd (Cin groups, spatial k x k)
  - Pointwise kernels Kp (1 x 1, Cin -> Cout)
1. Z = DepthwiseConv(X; groups=Cin)          # channel-wise spatial conv
2. Y = PointwiseConv(Z; kernel_size=1)      # channel mixing
Output: Y (N x Cout x H' x W')
```

ì´ ì˜ì‚¬ì½”ë“œëŠ” ë…¼ë¬¸ì´ Fig. 4ì—ì„œ ì œì‹œí•˜ëŠ” ê·¹ë‹¨ì  ë¶„í•´ì˜ ì—°ì‚°ì  ì˜ë¯¸ë¥¼ ê·¸ëŒ€ë¡œ ë°˜ì˜í•œë‹¤.

#### Parameter Count And FLOPs ê´€ì ì˜ ì •ë¦¬
íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì¤„ì–´ë“œëŠ” ê²ƒê³¼ ì‹¤ì œ ì—°ì‚°ëŸ‰(FLOPs)ì´ ì¤„ì–´ë“œëŠ” ê²ƒì€ ì„œë¡œ ê°•í•˜ê²Œ ì—°ê´€ë˜ì§€ë§Œ, ì™„ì „íˆ ê°™ì€ ê°œë…ì€ ì•„ë‹ˆë‹¤. Xception ë…¼ë¬¸ì´ ë§í•˜ëŠ” íš¨ìœ¨ì€ ë‘ ê´€ì  ëª¨ë‘ì—ì„œ ì´í•´í•  ìˆ˜ ìˆë‹¤.

ì…ë ¥ feature mapì˜ ê³µê°„ í¬ê¸°ë¥¼ $H\\times W$ë¼ê³  í•  ë•Œ, ì •ê·œ convolutionì˜ ëŒ€ëµì  MAC(Multiply-Accumulate) ìˆ˜ëŠ”

$$
H\\cdot W\\cdot k^2\\cdot C_{in}\\cdot C_{out}
$$

ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤. ë°˜ë©´ depthwise separable convolutionì€

$$
H\\cdot W\\cdot \\left(k^2\\cdot C_{in} + C_{in}\\cdot C_{out}\\right)
$$

ì— í•´ë‹¹í•œë‹¤. $C_{out}$ì´ ì¶©ë¶„íˆ í° ì¼ë°˜ì ì¸ êµ¬ê°„ì—ì„œëŠ” $k^2\\cdot C_{in}\\cdot C_{out}$ì™€ $C_{in}\\cdot C_{out}$ì˜ ì°¨ì´ê°€ í¬ê²Œ ë‚˜íƒ€ë‚˜ë¯€ë¡œ, depthwise separableì€ ê°™ì€ $C_{out}$ì„ ìœ ì§€í•˜ë©´ì„œë„ ê³„ì‚°ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤.

ë‹¤ë§Œ ë…¼ë¬¸ì´ Table 3ì—ì„œ ë³´ì—¬ì£¼ë“¯, ëª¨ë¸ ì „ì²´ ê´€ì ì˜ ì†ë„ëŠ” ë‹¨ìˆœí•œ FLOPsë§Œìœ¼ë¡œ ê²°ì •ë˜ì§€ ì•ŠëŠ”ë‹¤. depthwise convolutionì€ ì—°ì‚° íŒ¨í„´ì´ ì •ê·œ convolutionê³¼ ë‹¬ë¼, ë‹¹ì‹œì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì»¤ë„ ìµœì í™” ìˆ˜ì¤€ì— ë”°ë¼ ì‹¤ì œ steps/secondê°€ ë¶ˆë¦¬í•´ì§ˆ ìˆ˜ ìˆìŒì„ ë…¼ë¬¸ì´ ì§ì ‘ ì–¸ê¸‰í•œë‹¤.

#### Group Count $g$ë¡œ ë³´ëŠ” ì´ì‚° ìŠ¤í™íŠ¸ëŸ¼ì˜ ìˆ˜ì‹í™”
Fig. 3ì˜ segmented convolutionì„ êµ¬í˜„ ê´€ì ì—ì„œ ì •ë¦¬í•˜ë©´, channel dimensionì„ $g$ê°œ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” grouped convolutionìœ¼ë¡œ í•´ì„í•  ìˆ˜ ìˆë‹¤. $g$ë¥¼ ê·¸ë£¹ ìˆ˜ë¼ê³  í•  ë•Œ, grouped convolutionì˜ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ëŒ€ëµ

$$
\\frac{k^2\\cdot C_{in}\\cdot C_{out}}{g}
$$

ì´ ëœë‹¤. ì—¬ê¸°ì„œ

- $g=1$ì€ ì •ê·œ convolution  
- $g$ê°€ ì»¤ì§ˆìˆ˜ë¡ ì±„ë„ í˜¼í•©ì´ ì œí•œëœ í˜•íƒœ  

ë¡œ ì´ë™í•œë‹¤. ê·¹ë‹¨ì—ì„œ depthwise convolutionì€ $g=C_{in}$ì´ê³ , ì´ë•Œ ê° ê·¸ë£¹ì˜ ì¶œë ¥ ì±„ë„ì´ 1ê°œë¡œ ê³ ì •ë˜ëŠ” íŠ¹ìˆ˜í•œ í˜•íƒœë¡œ ì´í•´í•  ìˆ˜ ìˆë‹¤. ë…¼ë¬¸ì´ ë§í•˜ëŠ” ì—°ì†ì²´ëŠ”, ê²°êµ­ ì´ $g$ë¼ëŠ” ì„¤ê³„ ë³€ìˆ˜ë¥¼ í†µí•´ ì •ê·œ convolutionì—ì„œ depthwiseë¡œ ì´ë™í•˜ëŠ” ê²½ë¡œê°€ ì¡´ì¬í•œë‹¤ëŠ” ì£¼ì¥ìœ¼ë¡œ ì½ì„ ìˆ˜ ìˆë‹¤.

## 2ï¸âƒ£ Prior Work

### ğŸ”¸ CNN ì„¤ê³„ ê³„ë³´: VGG, Inception, ê·¸ë¦¬ê³  ì„¤ê³„ ë ˆì‹œí”¼ì˜ ì§„í™”
ë…¼ë¬¸ì€ CNN ì„¤ê³„ê°€ LeNetì—ì„œ AlexNet, VGGë¡œ ì´ì–´ì§€ë©° ê¹Šì´ë¥¼ í‚¤ìš°ëŠ” ë°©í–¥ìœ¼ë¡œ ë°œì „í•´ ì™”ìŒì„ ìƒê¸°í•œë‹¤. ì´í›„ Inception ê³„ì—´(GoogLeNet/Inception V2/V3, Inception-ResNet)ì€ Network In Networkì˜ ì˜í–¥ì„ ë°›ì•„, ë‹¨ìˆœí•œ stack êµ¬ì¡°ë¥¼ ë„˜ì–´ ëª¨ë“ˆ ë‹¨ìœ„ë¡œ ì—°ì‚°ì„ êµ¬ì„±í•˜ëŠ” ìŠ¤íƒ€ì¼ì„ ì •ì°©ì‹œì¼°ë‹¤.

ì´ ë§¥ë½ì€ Xceptionì´ ë‹¨ì§€ depthwise separable convolutionì„ ì±„íƒí•œ ëª¨ë¸ì´ ì•„ë‹ˆë¼, **Inception ê³„ì—´ì˜ ë‹¤ìŒ ë‹¨ê³„**ë¡œ ì œì•ˆëœë‹¤ëŠ” ë…¼ë¬¸ íë¦„ì„ ì´í•´í•˜ëŠ” ë° í•„ìš”í•˜ë‹¤.

#### VGG-Style Stackê³¼ì˜ êµ¬ì¡°ì  ìœ ì‚¬ì„±
ë…¼ë¬¸ì€ Xceptionì´ ëª‡ ê°€ì§€ ì¸¡ë©´ì—ì„œ VGG-16ê³¼ ë„ì‹ì ìœ¼ë¡œ ìœ ì‚¬í•˜ë‹¤ê³  ì–¸ê¸‰í•œë‹¤. ì´ ë§ì€ Xceptionì´ Inceptionì²˜ëŸ¼ ë³µì¡í•œ ë¶„ê¸° êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì „ì²´ì ìœ¼ë¡œëŠ” ë‹¤ì‹œ **ì„ í˜• stack** í˜•íƒœë¡œ ì •ë¦¬ëœë‹¤ëŠ” ì ì„ ê°•ì¡°í•œë‹¤.

1. stage ë‹¨ìœ„ë¡œ í•´ìƒë„ë¥¼ ì¤„ì´ë©° ì±„ë„ì„ ëŠ˜ë¦°ë‹¤.  
2. íŠ¹ì • ì±„ë„ í­ì—ì„œ ë™ì¼í•œ í˜•íƒœì˜ ë¸”ë¡ì„ ë°˜ë³µí•œë‹¤.  
3. ìµœì¢…ì ìœ¼ë¡œ global poolingê³¼ ë¶„ë¥˜ê¸°ë¡œ ì—°ê²°í•œë‹¤.  

ì°¨ì´ëŠ” ê° stageë¥¼ êµ¬ì„±í•˜ëŠ” ë ˆì´ì–´ê°€ ì •ê·œ convolutionì´ ì•„ë‹ˆë¼ depthwise separable convolutionì´ë¼ëŠ” ì ì´ë©°, ì´ ì°¨ì´ë¡œ ì¸í•´ íŒŒë¼ë¯¸í„° ì‚¬ìš© ë°©ì‹ì´ ë‹¬ë¼ì§„ë‹¤.

### ğŸ”¹ Depthwise Separable Convolutionì˜ ë“±ì¥ê³¼ í™•ì‚°
ë…¼ë¬¸ì€ depthwise separable convolutionì´ 2014ë…„ ë¬´ë µë¶€í„° ì‹ ê²½ë§ ì„¤ê³„ì—ì„œ ì‚¬ìš©ë˜ê¸° ì‹œì‘í–ˆìœ¼ë©°, TensorFlow ë“± í”„ë ˆì„ì›Œí¬ì— íš¨ìœ¨ì  êµ¬í˜„ì´ ì œê³µë˜ë©´ì„œ ë” ë„“ê²Œ ì“°ì´ê¸° ì‹œì‘í–ˆë‹¤ê³  ì •ë¦¬í•œë‹¤. ë˜í•œ Inception V1/V2ì˜ ì²« ë ˆì´ì–´ì— depthwise separable convolutionì´ ì‚¬ìš©ë˜ì—ˆë‹¤ëŠ” ë§¥ë½ì„ ì–¸ê¸‰í•˜ë©°, Xceptionì´ ì™„ì „íˆ ë‚¯ì„  ì—°ì‚°ì„ ë“¤ê³ ì˜¨ ê²ƒì´ ì•„ë‹ˆë¼ **ê¸°ì¡´ íë¦„ì˜ ì¼ë°˜í™”**ë¼ëŠ” ì ì„ ê°•ì¡°í•œë‹¤.

ì—¬ê¸°ì„œ ì¤‘ìš”í•œ êµ¬ë¶„ì´ í•˜ë‚˜ ìˆë‹¤. ë…¼ë¬¸ì€ deep learning í”„ë ˆì„ì›Œí¬ì—ì„œ separable convolutionì´ë¼ ë¶€ë¥´ëŠ” ê²ƒì´ **depthwise separable**ì„ ê°€ë¦¬í‚¤ëŠ” ê²½ìš°ê°€ ë§ìœ¼ë©°, ì˜ìƒì²˜ë¦¬ ë¬¸ë§¥ì—ì„œ separable convolutionì´ë¼ ë¶€ë¥´ëŠ” **spatially separable(ì˜ˆ: 7Ã—1, 1Ã—7)**ê³¼ëŠ” ë‹¤ë¥´ë‹¤ëŠ” ì ì„ ëª…ì‹œí•œë‹¤. Xceptionì€ ì „ìì˜ ì˜ë¯¸ë¥¼ ì‚¬ìš©í•œë‹¤.

#### Spatial Factorization And Depthwise Factorizationì˜ êµ¬ë¶„
Inception V3ë¥¼ ì½ì–´ë³¸ ë…ìëŠ” 7Ã—7 convolutionì„ 7Ã—1ê³¼ 1Ã—7ë¡œ ë‚˜ëˆ„ëŠ” ì‹ì˜ factorizationì„ ë– ì˜¬ë¦´ ìˆ˜ ìˆë‹¤. ì´ ê²½ìš°ì˜ ë¶„í•´ëŠ” ê³µê°„ ì¶•($k\\times k$)ì„ ë‘ ë‹¨ê³„ë¡œ ìª¼ê°œëŠ” ê²ƒìœ¼ë¡œ, ì±„ë„ í˜¼í•©($C_{in}\\to C_{out}$)ì€ ê° ë‹¨ê³„ì—ì„œ ì—¬ì „íˆ ì¼ì–´ë‚œë‹¤.

ë°˜ë©´ depthwise separable convolutionì—ì„œì˜ ë¶„í•´ëŠ” ê³µê°„ ë³€í™˜ê³¼ ì±„ë„ í˜¼í•©ì„ ë¶„ë¦¬í•œë‹¤. ë”°ë¼ì„œ ë‘ ë¶„í•´ëŠ” ë°©í–¥ì´ ë‹¤ë¥´ë‹¤.

- spatial factorization: ê³µê°„ convolutionì„ ë‘˜ë¡œ ìª¼ê°œëŠ” ë°©ì‹  
- depthwise factorization: ê³µê°„ ë³€í™˜ê³¼ ì±„ë„ í˜¼í•©ì„ ë¶„ë¦¬í•˜ëŠ” ë°©ì‹  

Xceptionì€ í›„ìë¥¼ ê¸°ë°˜ìœ¼ë¡œ Inception ëª¨ë“ˆì„ ì¬í•´ì„í•˜ë©°, ì´ êµ¬ë¶„ì„ ëª…í™•íˆ í•´ë‘ëŠ” ê²ƒì´ ì´í›„ ì‹¤í—˜ì—ì„œ ë…¼ì˜ë˜ëŠ” ì¤‘ê°„ activation ìŸì ì„ ì´í•´í•˜ëŠ” ë°ë„ ë„ì›€ì´ ëœë‹¤.

#### Depthwise Separable Convolutionì˜ ì„ í–‰ ì‚¬ë¡€ ì •ë¦¬
ë…¼ë¬¸ì€ depthwise separable convolutionê³¼ ê´€ë ¨ëœ ì„ í–‰ ì‚¬ë¡€ë¥¼ ë¹„êµì  êµ¬ì²´ì ìœ¼ë¡œ ì—´ê±°í•œë‹¤. ìš”ì§€ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

1. 2013ë…„ ë¬´ë µ Google Brainì—ì„œì˜ ì—°êµ¬ë¥¼ í†µí•´ depthwise separable convolutionì´ AlexNet ë³€í˜•ì— ì ìš©ë˜ì—ˆê³ , ì •í™•ë„ ë° ìˆ˜ë ´ ì†ë„ì—ì„œ ì´ë“ì´ ë³´ê³ ë˜ì—ˆë‹¤.  
2. ì´í›„ Inception V1/V2ì—ì„œ ì²« ë ˆì´ì–´ì— depthwise separable convolutionì´ ì‚¬ìš©ë˜ì—ˆë‹¤.  
3. MobileNet ê°™ì€ íš¨ìœ¨ ëª¨ë¸ì´ depthwise separable convolutionì„ í•µì‹¬ êµ¬ì„± ìš”ì†Œë¡œ ì‚¼ëŠ”ë‹¤.  
4. ë‹¤ë¥¸ ì—°êµ¬ë“¤ ì—­ì‹œ separable convolutionì„ í†µí•´ ëª¨ë¸ í¬ê¸°ì™€ ì—°ì‚° ë¹„ìš©ì„ ì¤„ì´ë ¤ëŠ” íë¦„ì„ ì´ì–´ ì™”ë‹¤.  

ì´ ë‚˜ì—´ì€ Xceptionì´ íŠ¹ì • íŠ¸ë¦­ì„ ìƒˆë¡œ ë„ì…í•œ ëª¨ë¸ì´ ì•„ë‹ˆë¼, ì—°ì‚°ì„ ë¶„í•´í•˜ëŠ” íë¦„ì´ ì¶©ë¶„íˆ ì„±ìˆ™í–ˆë‹¤ëŠ” ì „ì œ í•˜ì—ì„œ ê·¸ ë¶„í•´ë¥¼ ì•„í‚¤í…ì²˜ ì „ì²´ë¡œ í™•ì¥í•œ ëª¨ë¸ì´ë¼ëŠ” ë…¼ë¬¸ í¬ì§€ì…”ë‹ì„ ê°•í™”í•œë‹¤.

### ğŸ”¸ Residual Connectionì˜ ìœ„ì¹˜: ê¹Šì€ Stackì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í•™ìŠµ ì¥ì¹˜
Xceptionì€ ì „ì²´ êµ¬ì¡°ê°€ linear stackì— ê°€ê¹Œìš´ í˜•íƒœì´ê¸° ë•Œë¬¸ì—, í•™ìŠµ ì•ˆì •ì„±ì´ ë§¤ìš° ì¤‘ìš”í•˜ë‹¤. ë…¼ë¬¸ì€ Residual Connectionì„ ê¸°ì¡´ ì—°êµ¬(ResNet)ì—ì„œ ì˜¨ í•µì‹¬ êµ¬ì„±ìš”ì†Œë¡œ ìœ„ì¹˜ì‹œí‚¤ë©°, ì´í›„ ì‹¤í—˜ì—ì„œ residualì´ ìˆ˜ë ´ê³¼ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë³„ë„ë¡œ í™•ì¸í•œë‹¤.

#### Residual Connectionì˜ í•„ìš” ì¡°ê±´: ê¹Šì´ì™€ ë‹¨ìˆœ ë°˜ë³µ êµ¬ì¡°
Xceptionì˜ middle flowëŠ” ë™ì¼ í˜•íƒœ ëª¨ë“ˆì„ ë°˜ë³µí•˜ëŠ” êµ¬ì¡°ì´ë©°, ë…¼ë¬¸ì€ ì´ë¥¼ 8íšŒ ë°˜ë³µí•œë‹¤ê³  ëª…ì‹œí•œë‹¤. ë°˜ë³µì´ ê¹Šì–´ì§ˆìˆ˜ë¡ ìµœì í™”ëŠ” ì–´ë ¤ì›Œì§€ê¸° ì‰¬ìš´ë°, ì´ë•Œ residualì€

1. gradientê°€ ì „íŒŒë˜ëŠ” ê²½ë¡œë¥¼ ì§§ê²Œ ë§Œë“¤ê³   
2. ëª¨ë“ˆì´ í•™ìŠµí•´ì•¼ í•˜ëŠ” ë³€í™”ë¥¼ residual í˜•íƒœë¡œ ì œí•œí•˜ë©°  
3. ê¹Šì€ êµ¬ì¡°ì—ì„œì˜ ìˆ˜ë ´ ì†ë„ë¥¼ ê°œì„ í•˜ëŠ”  

ë°©í–¥ìœ¼ë¡œ ì‘ë™í•œë‹¤. ë…¼ë¬¸ì´ residualì˜ íš¨ê³¼ë¥¼ ë³„ë„ ì‹¤í—˜ìœ¼ë¡œ ë¶„ë¦¬í•´ í™•ì¸í•˜ëŠ” ê²ƒë„, Xception êµ¬ì¡°ê°€ ë‹¨ìˆœ ë°˜ë³µì„ í•µì‹¬ìœ¼ë¡œ ì‚¼ê¸° ë•Œë¬¸ì´ë‹¤.

## 3ï¸âƒ£ Xception Architecture

### ğŸ”¹ ì—°ì†ì²´ ê´€ì  ì •ì‹í™”: Segmented Convolutionì˜ ì´ì‚° ìŠ¤í™íŠ¸ëŸ¼
ë…¼ë¬¸ì€ ì •ê·œ convolutionê³¼ depthwise separable convolution ì‚¬ì´ì— **ì´ì‚° ìŠ¤í™íŠ¸ëŸ¼**ì´ ì¡´ì¬í•œë‹¤ê³  ì£¼ì¥í•œë‹¤. ì´ ìŠ¤í™íŠ¸ëŸ¼ì€ ê³µê°„ convolutionì„ ìˆ˜í–‰í•  ë•Œ ì±„ë„ ê³µê°„ì„ ëª‡ ê°œì˜ ë…ë¦½ segmentë¡œ ë¶„í• í•˜ëŠëƒì— ì˜í•´ ë§¤ê°œëœë‹¤.

- segmentê°€ 1ê°œë¼ë©´, ì±„ë„ì„ ì„ì–´ì„œ ê³µê°„ convolutionì„ ìˆ˜í–‰í•˜ëŠ” ì •ê·œ convolutionì— í•´ë‹¹í•œë‹¤.  
- segmentê°€ ì±„ë„ ìˆ˜ë§Œí¼(ì±„ë„ë‹¹ 1ê°œ)ì´ë¼ë©´, depthwise convolutionì´ ëœë‹¤.  
- Inception ëª¨ë“ˆì€ ê·¸ ì¤‘ê°„ ì§€ì ìœ¼ë¡œì„œ, ëª‡ ë°± ì±„ë„ì„ 3~4ê°œ segmentë¡œ ë‚˜ëˆ„ëŠ” ê²ƒê³¼ ìœ ì‚¬í•œ í•´ì„ì´ ê°€ëŠ¥í•˜ë‹¤.  

ì´ ê´€ì ì´ ë…¼ë¬¸ ì „ì²´ì˜ ì„¤ê³„ ë™ê¸°ì´ë©°, Xceptionì€ ì´ ìŠ¤í™íŠ¸ëŸ¼ì˜ ê·¹ë‹¨ì„ ì§ì ‘ ì„¤ê³„ë¡œ ì±„íƒí•œë‹¤.

### ğŸ”¸ Depthwise Separable Convolution ì •ì˜: Depthwise ì´í›„ Pointwise
ë…¼ë¬¸ì—ì„œ depthwise separable convolutionì€ ë‹¤ìŒ ë‘ ì—°ì‚°ì˜ í•©ì„±ìœ¼ë¡œ ì •ë¦¬ëœë‹¤.

1. **Depthwise Convolution**: ì…ë ¥ì˜ ê° ì±„ë„ì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ ê³µê°„ convolutionì„ ìˆ˜í–‰í•œë‹¤.  
2. **Pointwise Convolution(1Ã—1)**: depthwise ì¶œë ¥ ì±„ë„ë“¤ì„ ë‹¤ì‹œ ì„ í˜• ê²°í•©í•´ ìƒˆë¡œìš´ ì±„ë„ ê³µê°„ìœ¼ë¡œ ì‚¬ìƒí•œë‹¤.  

ì´ë¥¼ ë…¼ë¬¸ ìš©ì–´ëŒ€ë¡œ ì •ë¦¬í•˜ë©´ depthwise convolutionì€ spatial correlationì„, pointwise convolutionì€ cross-channel correlationì„ ì£¼ë¡œ ë‹´ë‹¹í•˜ë„ë¡ ë¶„í•´í•œ ê²ƒì´ë‹¤.

#### Depthwiseâ€“Pointwise ìˆœì„œì™€ ì¤‘ê°„ Non-Linearityì˜ ìŸì 
ë…¼ë¬¸ì€ Inceptionì˜ ì—°ì‚° ìˆœì„œ(1Ã—1 ì´í›„ spatial)ì™€, ì¼ë°˜ì  depthwise separable êµ¬í˜„ì˜ ìˆœì„œ(depthwise ì´í›„ 1Ã—1)ê°€ ë‹¤ë¥´ë‹¤ëŠ” ì ì„ ì§€ì í•œë‹¤. ë‹¤ë§Œ ìŠ¤íƒ í˜•íƒœë¡œ ë°˜ë³µ ì‚¬ìš©ë˜ëŠ” ìƒí™©ì—ì„œëŠ” ìˆœì„œ ì°¨ì´ê°€ ë³¸ì§ˆì ì´ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤ê³  ì£¼ì¥í•œë‹¤.

ë” ì¤‘ìš”í•œ ìŸì ì€ **ì¤‘ê°„ activationì˜ ìœ ë¬´**ë‹¤. Inceptionì—ì„œëŠ” ê° ë‹¨ê³„ ë’¤ì— ReLUê°€ ë“¤ì–´ê°€ì§€ë§Œ, depthwise separable convolutionì€ ì¢…ì¢… ì¤‘ê°„ non-linearity ì—†ì´ êµ¬í˜„ëœë‹¤. ë…¼ë¬¸ì€ ì´ ì°¨ì´ê°€ í•™ìŠµì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŒì„ ì§€ì í•˜ê³ , ì´í›„ ì‹¤í—˜(Fig. 10)ìœ¼ë¡œ ì´ë¥¼ ê²€ì¦í•œë‹¤.

#### Intermediate Activationì˜ ìœ„ì¹˜: Depthwise ì´í›„ Pointwise ì‚¬ì´
ë…¼ë¬¸ì´ ì‹¤í—˜ìœ¼ë¡œ ê²€ì¦í•˜ëŠ” ì¤‘ê°„ activationì€, depthwiseì™€ pointwise ì‚¬ì´ì— ë“¤ì–´ê°€ëŠ” non-linearityë¥¼ ì˜ë¯¸í•œë‹¤. ì´ ì§€ì ì€ ë‹¤ìŒ ì´ìœ ë¡œ ë¯¼ê°í•˜ë‹¤.

1. depthwise ë‹¨ê³„ëŠ” ì±„ë„ë³„ ê³µê°„ ë³€í™˜ì´ë¯€ë¡œ, ì±„ë„ ê°„ ì •ë³´ êµí™˜ì´ ì—†ë‹¤.  
2. pointwise ë‹¨ê³„ëŠ” ì±„ë„ í˜¼í•©ì„ ìˆ˜í–‰í•˜ë¯€ë¡œ, ì±„ë„ ê°„ ì •ë³´ ê²°í•©ì´ ì´ ë‹¨ê³„ì—ì„œ ì§‘ì¤‘ëœë‹¤.  
3. ë‘ ë‹¨ê³„ ì‚¬ì´ì—ì„œ activationì„ ì ìš©í•˜ë©´, ì±„ë„ í˜¼í•© ì´ì „ì— ì •ë³´ê°€ ì˜ë¦´ ìˆ˜ ìˆë‹¤.  

ë…¼ë¬¸ì€ Fig. 10ì—ì„œ ReLU/ELU ë“±ì„ ë„£ëŠ” ê²ƒì´ ì˜¤íˆë ¤ í•´ë¡­ë‹¤ëŠ” ê²°ê³¼ë¥¼ í†µí•´, Xception ê³„ì—´ì—ì„œëŠ” ì¤‘ê°„ activationì´ í•„ìˆ˜ì ì´ì§€ ì•ŠìŒì„ ì£¼ì¥í•œë‹¤.

### ğŸ”¹ Xceptionì˜ í•µì‹¬ ê°€ì„¤: ì±„ë„ ìƒê´€ê´€ê³„ì™€ ê³µê°„ ìƒê´€ê´€ê³„ì˜ ì™„ì „ ë¶„ë¦¬ ê°€ëŠ¥ì„±
ë…¼ë¬¸ì€ Xceptionì˜ ê°€ì„¤ì„ ë‹¤ìŒì²˜ëŸ¼ ì„ ì–¸í•œë‹¤. Feature mapì—ì„œì˜ cross-channel correlationê³¼ spatial correlationì€ **ì™„ì „íˆ ë¶„ë¦¬í•´ ë§¤í•‘í•  ìˆ˜ ìˆë‹¤**. ì¦‰, ë¶„í•´ë¥¼ ì¤‘ê°„ ì •ë„ë¡œë§Œ ìˆ˜í–‰í•˜ëŠ” Inceptionë³´ë‹¤, ë¶„í•´ë¥¼ ê·¹ë‹¨ìœ¼ë¡œ ë°€ì–´ë¶™ì¸ depthwise separable convolutionì´ ë” ì í•©í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤.

ì´ ê°€ì„¤ì€ Xceptionì´ë¼ëŠ” ì´ë¦„ê³¼ ë°”ë¡œ ì—°ê²°ëœë‹¤. Inception ê°€ì„¤ì„ ë” ê°•í•˜ê²Œ ë§Œë“  í˜•íƒœì´ë¯€ë¡œ, Extreme Inceptionì´ë¼ëŠ” ì˜ë¯¸ì—ì„œ Xceptionì´ë¼ê³  ë¶€ë¥¸ë‹¤.

### ğŸ”¸ ì „ì²´ êµ¬ì¡°: Entry Flow, Middle Flow, Exit Flow
ë…¼ë¬¸ì€ Xceptionì„ 3ê°œì˜ íë¦„ìœ¼ë¡œ ì„¤ëª…í•œë‹¤.

1. **Entry Flow**: ì…ë ¥ì—ì„œ ì´ˆê¸° íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê³  í•´ìƒë„ë¥¼ ì¤„ì´ë©° ì±„ë„ ìˆ˜ë¥¼ í‚¤ìš´ë‹¤.  
2. **Middle Flow**: ë™ì¼í•œ í˜•íƒœì˜ ëª¨ë“ˆì„ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µí•´ í‘œí˜„ë ¥ì„ í™•ì¥í•œë‹¤.  
3. **Exit Flow**: ìµœì¢… íŠ¹ì§•ì„ ì •ë¦¬í•˜ê³  ë¶„ë¥˜ headë¡œ ì—°ê²°í•œë‹¤.  

ë…¼ë¬¸ì€ Fig. 5ì—ì„œ Xception ì•„í‚¤í…ì²˜ë¥¼ ì œì‹œí•˜ë©°, ë°ì´í„°ê°€ entry â†’ middle(8íšŒ ë°˜ë³µ) â†’ exit ìˆœìœ¼ë¡œ íë¥¸ë‹¤ê³  ëª…ì‹œí•œë‹¤. ë˜í•œ ë‹¤ì´ì–´ê·¸ë¨ì—ì„œëŠ” ìƒëµë˜ì§€ë§Œ, ëª¨ë“  Convolution ë° Separable Convolution ë’¤ì— Batch Normalizationì´ ì¡´ì¬í•œë‹¤ê³  ì„¤ëª…í•œë‹¤.

(Fig. 5: Xception ì „ì²´ ì•„í‚¤í…ì²˜(Entry Flow, Middle FlowÃ—8, Exit Flow), BN í‘œê¸° ìƒëµ)  

#### Entryâ€“Middleâ€“Exit ë¶„í•´ì˜ ì„¤ê³„ íš¨ê³¼
Entry, Middle, Exitë¡œ êµ¬ì¡°ë¥¼ ë¶„í•´í•˜ëŠ” ë°©ì‹ì€ Inception ê³„ì—´ì—ì„œ ì´ë¯¸ ìì£¼ ë“±ì¥í•˜ì§€ë§Œ, Xceptionì—ì„œëŠ” ë¶„ê¸° êµ¬ì¡°ê°€ ì‚¬ë¼ì§€ê³  ì„ í˜• ìŠ¤íƒ í˜•íƒœë¡œ ì •ë¦¬ë˜ì—ˆê¸° ë•Œë¬¸ì— ì´ ë¶„í•´ê°€ ë” ì§ì ‘ì ìœ¼ë¡œ ì‘ë™í•œë‹¤.

- Entry FlowëŠ” í•´ìƒë„ë¥¼ ë¹ ë¥´ê²Œ ì¤„ì´ë©° ì €ìˆ˜ì¤€ íŒ¨í„´ì„ ì±„ë„ ì¶•ìœ¼ë¡œ í™•ì¥í•´, ì´í›„ depthwise separable stackì´ ë‹¤ë£° í‘œí˜„ ê³µê°„ì„ ë§Œë“ ë‹¤.  
- Middle FlowëŠ” ë™ì¼í•œ ì±„ë„ í­ì—ì„œ ë°˜ë³µë˜ëŠ” ë³€í™˜ì„ í†µí•´ í‘œí˜„ë ¥ì„ ëˆ„ì í•œë‹¤. ë°˜ë³µ êµ¬ì¡°ê°€ ê°•í•˜ë¯€ë¡œ, residualì˜ ì—­í• ì´ ë‘ë“œëŸ¬ì§„ë‹¤.  
- Exit FlowëŠ” ë§ˆì§€ë§‰ downsampling ì´í›„ ì±„ë„ í™•ì¥ì„ í†µí•´ ë¶„ë¥˜ headë¡œ ì „ë‹¬í•  ê³ ìˆ˜ì¤€ íŠ¹ì§•ì„ ì •ë¦¬í•œë‹¤.  

ë…¼ë¬¸ì´ ì „ì²´ baseë¥¼ 36 convolutional layerë¡œ ì„¤ëª…í•˜ê³  ì´ë¥¼ 14 modulesë¡œ ë¬¶ì–´ ë§í•˜ëŠ” ê²ƒë„, ì‹¤ì œë¡œëŠ” ì´ëŸ° ë°˜ë³µ ê°€ëŠ¥í•œ ë‹¨ìœ„ê°€ ëª…í™•í•˜ë‹¤ëŠ” ì ì„ ê°•ì¡°í•˜ê¸° ìœ„í•¨ìœ¼ë¡œ ì½ì„ ìˆ˜ ìˆë‹¤.

### ğŸ”¹ ëª¨ë“ˆ êµ¬ì„±: Residual Connectionì„ ë‘ë¥¸ Depthwise Separable Stack
ë…¼ë¬¸ì€ Xceptionì˜ feature extraction baseê°€ 36ê°œì˜ convolutional layerë¡œ êµ¬ì„±ë˜ì–´ ìˆê³ , ì´ë¥¼ 14ê°œì˜ ëª¨ë“ˆë¡œ ë¬¶ëŠ”ë‹¤ê³  ì„¤ëª…í•œë‹¤. ê·¸ë¦¬ê³  ì²«/ë§ˆì§€ë§‰ ëª¨ë“ˆì„ ì œì™¸í•œ ëª¨ë“  ëª¨ë“ˆì— linear residual connectionì„ ë‘”ë‹¤ê³  ëª…ì‹œí•œë‹¤.

ì´ êµ¬ì„±ì´ ì£¼ëŠ” ì„¤ê³„ì  íš¨ê³¼ëŠ” ë‹¤ìŒì²˜ëŸ¼ í•´ì„í•  ìˆ˜ ìˆë‹¤.

1. ëª¨ë“ˆ ë‹¨ìœ„ì˜ ë°˜ë³µì€ êµ¬ì¡°ì  ë‹¨ìˆœì„±ì„ ë§Œë“ ë‹¤.  
2. residualì€ ê¹Šì€ ë°˜ë³µì—ì„œì˜ ìµœì í™”ë¥¼ ì•ˆì •í™”í•œë‹¤.  
3. depthwise separableì€ ê° ë ˆì´ì–´ì˜ ì±„ë„/ê³µê°„ ì²˜ë¦¬ ì—­í• ì„ ë¶„í•´í•œë‹¤.  

#### BN í‘œê¸° ìƒëµì´ ì˜ë¯¸í•˜ëŠ” ê²ƒ: ì—°ì‚° ë‹¨ìœ„ì˜ ë°˜ë³µ íŒ¨í„´
ë…¼ë¬¸ì€ Fig. 5ì—ì„œ BNì„ ë‹¤ì´ì–´ê·¸ë¨ì—ì„œ ìƒëµí•œë‹¤ê³  ëª…ì‹œí•œë‹¤. ì´ ë¬¸ì¥ì€ ë‹¨ìˆœí•œ í¸ì˜ê°€ ì•„ë‹ˆë¼, Xceptionì˜ êµ¬í˜„ ë‹¨ìœ„ê°€ ì‚¬ì‹¤ìƒ

- Separable Convolution  
- Batch Normalization  
- Activation  

ì˜ ë°˜ë³µ íŒ¨í„´ìœ¼ë¡œ êµ¬ì„±ëœë‹¤ëŠ” ì‚¬ì‹¤ì„ ê°•ì¡°í•œë‹¤. ì¦‰, Xceptionì„ ì´í•´í•  ë•ŒëŠ” ë¸”ë¡ ë‚´ë¶€ì˜ ì„¸ë¶€ ì—°ì‚° ë‚˜ì—´ë³´ë‹¤, depthwise separable stackì´ë¼ëŠ” í° í˜•íƒœì™€ ê·¸ ìœ„ì— residualì´ ê°ì‹¸ëŠ” êµ¬ì¡°ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì½ëŠ” ê²ƒì´ ì ì ˆí•˜ë‹¤.

#### Feature Extraction Baseì™€ Classifier Headì˜ ê²°í•© ë°©ì‹
ë…¼ë¬¸ì€ 36ê°œì˜ convolutional layerê°€ feature extraction baseë¥¼ í˜•ì„±í•˜ê³ , ê·¸ ë’¤ì— logistic regression layerë¥¼ ë‘”ë‹¤ê³  ì„¤ëª…í•œë‹¤. ë˜í•œ ì„ íƒì ìœ¼ë¡œ logistic regression ì´ì „ì— fully-connected layerë¥¼ ì‚½ì…í•  ìˆ˜ ìˆìŒì„ ì–¸ê¸‰í•˜ë©°, ì´ëŠ” JFT ì‹¤í—˜ì—ì„œ ë¶„ê¸° ë¹„êµì˜ í˜•íƒœë¡œ ë“±ì¥í•œë‹¤.

ì´ êµ¬ì¡°ëŠ” ë‹¤ìŒì²˜ëŸ¼ í•´ì„í•  ìˆ˜ ìˆë‹¤.

1. baseëŠ” ê³µê°„ í•´ìƒë„ë¥¼ ì¤„ì´ë©° ê³ ìˆ˜ì¤€ íŠ¹ì§•ì„ ë§Œë“ ë‹¤.  
2. headëŠ” ì´ íŠ¹ì§•ì„ í´ë˜ìŠ¤ ì ìˆ˜ë¡œ ì„ í˜• ë¶„ë¥˜í•œë‹¤.  
3. FC ì‚½ì… ì—¬ë¶€ëŠ” headì˜ ìš©ëŸ‰ì„ ë°”ê¾¸ë©°, ë°ì´í„° ê·œëª¨ì— ë”°ë¼ íš¨ê³¼ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆë‹¤.  

## 4ï¸âƒ£ Experimental Evaluation

### ğŸ”¸ í‰ê°€ í”„ë¡œí† ì½œ: Single Crop, Single Model ê¸°ì¤€ ë¹„êµ
ë…¼ë¬¸ì€ ImageNet ê²°ê³¼ë¥¼ single crop, single modelë¡œ í‰ê°€í–ˆìŒì„ ëª…ì‹œí•œë‹¤. ë˜í•œ Inception V3ì—ì„œ ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” auxiliary towerëŠ” ë¹„êµì˜ ë‹¨ìˆœì„±ì„ ìœ„í•´ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ë‹¤ê³  ì–¸ê¸‰í•œë‹¤.

#### Controlled Comparisonì˜ ì˜ë¯¸
ì´ í‰ê°€ëŠ” ë‹¨ìˆœí•œ ê´€í–‰ì  ë³´ê³ ê°€ ì•„ë‹ˆë¼, ë…¼ë¬¸ì´ ì„¸ìš°ë ¤ëŠ” ë…¼ì¦ êµ¬ì¡°ì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ëœë‹¤. ë…¼ë¬¸ì€ Xceptionê³¼ Inception V3ì˜ ì„±ëŠ¥ ì°¨ì´ë¥¼ ëª¨ë¸ ìš©ëŸ‰ì˜ ì°¨ì´ê°€ ì•„ë‹ˆë¼ êµ¬ì¡°ì  ì°¨ì´ë¡œ í•´ì„í•˜ë ¤ê³  í•œë‹¤. ë”°ë¼ì„œ

- ë™ì¼í•œ single crop ì¡°ê±´ìœ¼ë¡œ inference time augmentation íš¨ê³¼ë¥¼ ë°°ì œí•˜ê³   
- single modelë¡œ ensemble íš¨ê³¼ë¥¼ ë°°ì œí•˜ê³   
- auxiliary towerë¥¼ ì œê±°í•´ Inception ìª½ì˜ ì¶”ê°€ ì •ê·œí™” ê¸°ì œë¥¼ ì œê±°í•œë‹¤  

ëŠ” í†µì œ ì¡°ê±´ì„ ëª…ì‹œí•œ ê²ƒìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆë‹¤. ì´ í†µì œëŠ” Table 1â€“3ì˜ ë¹„êµê°€ í•´ì„ ê°€ëŠ¥í•˜ë„ë¡ ë§Œë“œëŠ” ìµœì†Œí•œì˜ ì¥ì¹˜ë‹¤.

### ğŸ”¹ ë°ì´í„°ì…‹: ImageNetê³¼ JFT
ë…¼ë¬¸ì€ ë‘ ë°ì´í„°ì…‹ì—ì„œ ì„±ëŠ¥ì„ ë¹„êµí•œë‹¤.

- **ImageNet**: ê³µê°œ ë¶„ë¥˜ ë°ì´í„°ì…‹, ë…¼ë¬¸ì€ validation set ê²°ê³¼ë¥¼ ë³´ê³ í•œë‹¤.  
- **JFT**: ì•½ 3.5ì–µ ì´ë¯¸ì§€ì™€ 1.7ë§Œ í´ë˜ìŠ¤ì˜ ëŒ€ê·œëª¨ ë‚´ë¶€ ë°ì´í„°ì…‹. í‰ê°€ ì§€í‘œëŠ” FastEval14kì˜ MAP@100ì´ë©°, í´ë˜ìŠ¤ë³„ ë¹ˆë„ ê¸°ë°˜ ê°€ì¤‘ì„ í¬í•¨í•œë‹¤ê³  ì„¤ëª…í•œë‹¤.  

Xceptionì´ ImageNetë³´ë‹¤ JFTì—ì„œ ë” í° ê°œì„ ì„ ë³´ì¸ë‹¤ëŠ” ì ì€, êµ¬ì¡°ê°€ ë” ì¼ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ê²ƒì¸ì§€ í˜¹ì€ íŠ¹ì • ë ˆì‹œí”¼ì— ëœ ë§ì¶°ì§„ ê²ƒì¸ì§€ì— ëŒ€í•œ í•´ì„ í¬ì¸íŠ¸ê°€ ëœë‹¤.

#### FastEval14k And MAP@100ì˜ ì •ì˜ì  ê´€ì 
ë…¼ë¬¸ì€ FastEval14kê°€ ì•½ 14,000ì¥ì˜ ì´ë¯¸ì§€ë¡œ êµ¬ì„±ë˜ë©°, í´ë˜ìŠ¤ê°€ ì•½ 6,000ê°œì´ê³  ì´ë¯¸ì§€ë‹¹ í‰ê·  ë¼ë²¨ ìˆ˜ê°€ 36.5ê°œë¼ê³  ëª…ì‹œí•œë‹¤. ì´ëŠ” ë‹¨ì¼ ë¼ë²¨ ë¶„ë¥˜(ImageNet)ì™€ ë‹¬ë¦¬, í•œ ì´ë¯¸ì§€ê°€ ì—¬ëŸ¬ í´ë˜ìŠ¤ë¥¼ ë™ì‹œì— ê°–ëŠ” multi-label settingì„ì„ ì˜ë¯¸í•œë‹¤.

MAP@100ì€ ê° ì´ë¯¸ì§€ì—ì„œ ìƒìœ„ 100ê°œ ì˜ˆì¸¡ì„ ì‚¬ìš©í•´ Average Precisionì„ ê³„ì‚°í•˜ê³ , ì´ë¥¼ í‰ê· ë‚´ëŠ” ë°©ì‹ì´ë‹¤. í‘œì¤€ì ì¸ ì •ì˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì“°ë©´ ë‹¤ìŒì²˜ëŸ¼ ì •ë¦¬í•  ìˆ˜ ìˆë‹¤.

í•œ ì´ë¯¸ì§€ $x$ì— ëŒ€í•´ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í´ë˜ìŠ¤ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸ë¥¼ $c_1,\\dots,c_{100}$ì´ë¼ í•˜ê³ , ì •ë‹µ ë¼ë²¨ ì§‘í•©ì„ $Y$ë¼ í•˜ì. ê·¸ëŸ¬ë©´ precision@këŠ”

$$
P(k)=\\frac{\\left|\\{c_i\\mid i\\le k,\\ c_i\\in Y\\}\\right|}{k}
$$

ë¡œ ì •ì˜í•  ìˆ˜ ìˆë‹¤. ì´ë¥¼ ì‚¬ìš©í•´ Average Precision@100ì„

$$
AP@100 = \\frac{1}{|Y|}\\sum_{k=1}^{100} P(k)\\cdot \\mathbb{1}[c_k\\in Y]
$$

ë¡œ ë‘˜ ìˆ˜ ìˆê³ , MAP@100ì€ ë°ì´í„°ì…‹ ì „ì²´ì— ëŒ€í•´ $AP@100$ì„ í‰ê· ë‚¸ ê°’ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆë‹¤. ë…¼ë¬¸ì€ ì—¬ê¸°ì— ë”í•´, í´ë˜ìŠ¤ë³„ë¡œ ìì£¼ ë“±ì¥í•˜ëŠ” ë¼ë²¨ì— ë” í° ê°€ì¤‘ì„ ë‘ëŠ” ê°€ì¤‘ MAP@100ì„ ì‚¬ìš©í•œë‹¤ê³  ì„¤ëª…í•œë‹¤.

### ğŸ”¸ ìµœì í™” ë° ì •ê·œí™” êµ¬ì„±: ImageNet ëŒ€ë¹„ JFT ì„¤ì •
ë…¼ë¬¸ì€ ImageNetê³¼ JFTì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ìµœì í™” êµ¬ì„±ì„ ì‚¬ìš©í–ˆë‹¤ê³  ëª…ì‹œí•œë‹¤.

#### ImageNet ìµœì í™”
- Optimizer: SGD  
- Momentum: 0.9  
- Initial Learning Rate: 0.045  
- Learning Rate Decay: 2 epochë§ˆë‹¤ 0.94 ë¹„ìœ¨ë¡œ ê°ì†Œ  

#### JFT ìµœì í™”
- Optimizer: RMSProp  
- Momentum: 0.9  
- Initial Learning Rate: 0.001  
- Learning Rate Decay: 3,000,000 samplesë§ˆë‹¤ 0.9 ë¹„ìœ¨ë¡œ ê°ì†Œ  

ë˜í•œ weight decayëŠ” Inception V3ì˜ 4e-5ê°€ Xceptionì— ë¶€ì ì ˆí–ˆê³  1e-5ë¥¼ ì‚¬ìš©í–ˆë‹¤ê³  ë°íŒë‹¤. Dropoutì€ ImageNetì—ì„œëŠ” 0.5ë¡œ ì‚¬ìš©í–ˆì§€ë§Œ, JFTì—ì„œëŠ” ë°ì´í„°ê°€ ë§¤ìš° ì»¤ ê³¼ì í•© ê°€ëŠ¥ì„±ì´ ë‚®ì•„ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ë‹¤ê³  ì„œìˆ í•œë‹¤.

#### ë™ì¼ ìµœì í™” ì„¤ì • ì‚¬ìš©ì˜ í•´ì„
ë…¼ë¬¸ì€ ì¤‘ìš”í•œ ë‹¨ì„œë¥¼ í•˜ë‚˜ ë” ë‘”ë‹¤. ImageNetê³¼ JFT ê°ê°ì— ëŒ€í•´, Xceptionê³¼ Inception V3ëŠ” ë™ì¼í•œ ìµœì í™” ì„¤ì •ì„ ì‚¬ìš©í–ˆìœ¼ë©°, ì´ ì„¤ì •ì€ Inception V3ì— ë§ì¶° íŠœë‹ëœ ê²ƒì´ë¼ê³  ëª…ì‹œí•œë‹¤. ì´ëŠ”

- Xceptionì´ Inception V3ì˜ ìµœì í™” ë ˆì‹œí”¼ í•˜ì—ì„œë„ ê²½ìŸë ¥ì´ ìˆìŒì„ ë³´ì—¬ì£¼ë©´ì„œ  
- ë™ì‹œì— Fig. 6ì—ì„œ ê´€ì¸¡ë˜ëŠ” training profile ì°¨ì´ê°€, Xceptionì— ëŒ€í•´ ìµœì ì´ ì•„ë‹ ìˆ˜ ìˆìŒì„ ì¸ì •í•˜ëŠ”  

ë°©í–¥ì˜ ì„œìˆ ì´ë‹¤. ë”°ë¼ì„œ ImageNetì—ì„œì˜ ì†Œí­ ê°œì„ ì€ êµ¬ì¡°ì  ì°¨ì´ê°€ ì¶©ë¶„íˆ í° ê°œì„ ì„ ë§Œë“¤ì§€ ëª»í–ˆë‹¤ëŠ” ê²°ë¡ ì´ë¼ê¸°ë³´ë‹¤, ìµœì í™” ì¸¡ë©´ì˜ ì—¬ì§€ê°€ ë‚¨ì•„ ìˆë‹¤ëŠ” í˜•íƒœë¡œ ì½ì„ ìˆ˜ ìˆë‹¤.

#### Polyak Averaging At Inferenceì˜ ì˜ë¯¸
ë…¼ë¬¸ì€ ë‘ ë°ì´í„°ì…‹ ëª¨ë‘ì—ì„œ inference ì‹œ Polyak averagingì„ ì‚¬ìš©í–ˆë‹¤ê³  ëª…ì‹œí•œë‹¤. Polyak averagingì€ í•™ìŠµ ê³¼ì •ì—ì„œ ì–»ì€ íŒŒë¼ë¯¸í„°ë“¤ì„ ë‹¨ìˆœíˆ ë§ˆì§€ë§‰ stepì˜ íŒŒë¼ë¯¸í„°ë¡œ ê³ ì •í•˜ì§€ ì•Šê³ , ì—¬ëŸ¬ stepì— ê±¸ì³ í‰ê· ë‚¸ íŒŒë¼ë¯¸í„°ë¡œ í‰ê°€í•˜ëŠ” ë°©ì‹ì´ë‹¤. ì§ê´€ì ìœ¼ë¡œëŠ”

- SGD ê³„ì—´ ìµœì í™”ê°€ ë§Œë“œëŠ” íŒŒë¼ë¯¸í„° ì§„ë™ì„ í‰ê· í™”í•´  
- ë” í‰í‰í•œ ì§€ì—­ì˜ í•´ë¥¼ ì„ íƒí•˜ë„ë¡ ìœ ë„í•´  
- ì¼ë°˜í™” ì„±ëŠ¥ì„ ì†Œí­ ì•ˆì •í™”í•˜ëŠ”  

íš¨ê³¼ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìˆë‹¤. ë…¼ë¬¸ì´ ì´ë¥¼ ëª…ì‹œí•œ ê²ƒì€, Table 1â€“2ì˜ ìˆ˜ì¹˜ê°€ ë‹¨ìˆœíˆ ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸ê°€ ì•„ë‹ˆë¼ íŠ¹ì •í•œ í‰ê°€ ë ˆì‹œí”¼ì— ê¸°ë°˜í•œë‹¤ëŠ” ì ì„ ë…ìê°€ ì¶”ì í•  ìˆ˜ ìˆê²Œ í•˜ê¸° ìœ„í•¨ì´ë‹¤.

#### Training Infrastructure And Convergence Status
ë…¼ë¬¸ì€ ì‹¤í—˜ ì¸í”„ë¼ì™€ í•™ìŠµ ë°©ì‹ê¹Œì§€ ë¹„êµì  êµ¬ì²´ì ìœ¼ë¡œ ê³µê°œí•œë‹¤. ëª¨ë“  ë„¤íŠ¸ì›Œí¬ëŠ” TensorFlowë¡œ êµ¬í˜„í–ˆìœ¼ë©°, ê° ì‹¤í—˜ì€ 60ê°œì˜ NVIDIA K80 GPUì—ì„œ í•™ìŠµí–ˆë‹¤. ë‹¤ë§Œ ë°ì´í„°ì…‹ì— ë”°ë¼ ë³‘ë ¬í™” ë°©ì‹ì´ ë‹¬ëë‹¤.

1. ImageNet: data parallelism + synchronous gradient descent  
2. JFT: asynchronous gradient descent  

ë…¼ë¬¸ì€ ImageNetì—ì„œëŠ” ìµœê³  ì„±ëŠ¥ì„ ìœ„í•´ synchronousë¥¼ ì„ íƒí–ˆê³ , JFTì—ì„œëŠ” í•™ìŠµ ì†ë„ë¥¼ ìœ„í•´ asynchronousë¥¼ ì‚¬ìš©í–ˆë‹¤ê³  ì„¤ëª…í•œë‹¤. ë˜í•œ ì‹¤í—˜ ì†Œìš” ì‹œê°„ë„ í•¨ê»˜ ì œì‹œí•œë‹¤.

1. ImageNet: ì‹¤í—˜ë‹¹ ì•½ 3ì¼  
2. JFT: ì‹¤í—˜ë‹¹ 1ê°œì›” ì´ìƒ  

ê·¸ë¦¬ê³  JFTëŠ” ì™„ì „ ìˆ˜ë ´ê¹Œì§€ í•™ìŠµí•˜ì§€ ì•Šì•˜ìœ¼ë©°, ì™„ì „ ìˆ˜ë ´ì—ëŠ” ì‹¤í—˜ë‹¹ 3ê°œì›” ì´ìƒì´ ê±¸ë¦´ ê²ƒì´ë¼ê³  ì–¸ê¸‰í•œë‹¤. ì´ ë‹¨ì„œëŠ” Table 2ì˜ ì ˆëŒ€ê°’ í•´ì„ì— ì˜í–¥ì„ ì¤€ë‹¤. JFT ê²°ê³¼ëŠ” ìµœì¢… ìˆ˜ë ´ê°’ì´ë¼ê¸°ë³´ë‹¤, ì£¼ì–´ì§„ ì‹œê°„ ì˜ˆì‚° ì•„ë˜ì—ì„œì˜ ë¹„êµë¡œ ì´í•´í•˜ëŠ” í¸ì´ ë” ì•ˆì „í•˜ë‹¤.

### ğŸ”¹ ImageNet ë¹„êµ: Inception V3 ëŒ€ë¹„ ì†Œí­ ê°œì„ 
ë…¼ë¬¸ì€ Table 1ì—ì„œ ImageNet single crop ì„±ëŠ¥ì„ ë¹„êµí•œë‹¤. VGG-16 ë° ResNet-152ëŠ” ë§¥ë½ ì œê³µìš©ìœ¼ë¡œ í•¨ê»˜ ì œì‹œë˜ë©°, ë¹„êµì˜ í•µì‹¬ì€ Inception V3ì™€ Xceptionì´ë‹¤.

(Table 1: ImageNet Single Crop ì„±ëŠ¥ ë¹„êµ(Top-1, Top-5))  

| Model | Top-1 Accuracy | Top-5 Accuracy |
|---|---:|---:|
| VGG-16 | 0.715 | 0.901 |
| ResNet-152 | 0.770 | 0.933 |
| Inception V3 | 0.782 | 0.941 |
| Xception | 0.790 | 0.945 |

ì´ í‘œê°€ ì „ë‹¬í•˜ëŠ” ë…¼ì§€ëŠ” ë‘ ê°€ì§€ë‹¤.

1. Xceptionì€ Inception V3ì™€ íŒŒë¼ë¯¸í„° ê·œëª¨ê°€ ìœ ì‚¬í•œ ì¡°ê±´ì—ì„œ Top-1/Top-5 ëª¨ë‘ ê°œì„ ì„ ë³´ì¸ë‹¤.  
2. ê°œì„  í­ì€ ImageNetì—ì„œëŠ” í¬ì§€ ì•Šì§€ë§Œ, êµ¬ì¡°ì  ëŒ€ì²´(Inceptionâ†’Depthwise Separable)ê°€ ìœ íš¨í•¨ì„ ë³´ì—¬ì¤€ë‹¤.  

(Fig. 6: ImageNetì—ì„œì˜ í•™ìŠµ ê³¡ì„ (Training Profile))  

#### Table 1 í•´ì„: ì ˆëŒ€ ì„±ëŠ¥ê³¼ ì„¤ê³„ ë…¼ì¦ì˜ ì—°ê²°
Table 1ì˜ í•µì‹¬ ë¹„êµëŠ” Inception V3ì™€ Xceptionì˜ ê·¼ì ‘í•œ ìŠ¤ì¼€ì¼ì—ì„œì˜ ì„±ëŠ¥ ì°¨ì´ë‹¤. Top-1ì´ 0.782ì—ì„œ 0.790ìœ¼ë¡œ, Top-5ê°€ 0.941ì—ì„œ 0.945ë¡œ ì´ë™í•˜ëŠ” ê²ƒì€ í° í­ì˜ ë„ì•½ì€ ì•„ë‹ˆì§€ë§Œ, ë‹¤ìŒ ì‚¬ì‹¤ì„ ë™ì‹œì— ë§Œì¡±í•œë‹¤.

1. íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ë¹„ìŠ·í•œ ìƒíƒœì—ì„œì˜ ê°œì„ ì´ë¯€ë¡œ, ë‹¨ìˆœíˆ ë” í° ëª¨ë¸ì„ ì“´ ê²°ê³¼ë¡œ í™˜ì›í•˜ê¸° ì–´ë µë‹¤.  
2. Inception ëª¨ë“ˆì˜ ë¶„ê¸° êµ¬ì¡°ë¥¼ ì œê±°í•˜ê³ ë„ ì„±ëŠ¥ì´ ìœ ì§€ë˜ë©° ì˜¤íˆë ¤ ì¢‹ì•„ì§ˆ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤.  

ì´ ë‘ ì¡°ê±´ì´ ì¶©ì¡±ë˜ë©´, ë…¼ë¬¸ì´ ì£¼ì¥í•˜ëŠ” Extreme Inceptionì´ë¼ëŠ” ê´€ì ì´ ë‹¨ì§€ ë¹„ìœ ê°€ ì•„ë‹ˆë¼ ì‹¤ì œ ì„¤ê³„ ê°€ì„¤ë¡œì„œ ê¸°ëŠ¥í•œë‹¤ëŠ” ê·¼ê±°ê°€ ëœë‹¤.

### ğŸ”¸ JFT ë¹„êµ: í° ë°ì´í„°ì—ì„œì˜ ë” í° ì´ë“
ë…¼ë¬¸ì€ JFTì—ì„œ Xceptionì´ Inception V3 ëŒ€ë¹„ 4.3%ì˜ ìƒëŒ€ ê°œì„ ì„ ë³´ì¸ë‹¤ê³  ì •ë¦¬í•œë‹¤. Table 2ëŠ” fully-connected layer í¬í•¨ ì—¬ë¶€ì— ë”°ë¼ ë„¤ ê°€ì§€ ì¡°í•©ì„ ë¹„êµí•œë‹¤.

(Table 2: JFT FastEval14k MAP@100 ë¹„êµ(Single Crop, Single Model))  

| Model | FastEval14k MAP@100 |
|---|---:|
| Inception V3 (No FC) | 6.36 |
| Xception (No FC) | 6.70 |
| Inception V3 (With FC) | 6.50 |
| Xception (With FC) | 6.78 |

ë…¼ë¬¸ì€ JFTì—ì„œì˜ ê°œì„ ì´ ImageNetë³´ë‹¤ í›¨ì”¬ í° ì´ìœ ë¥¼, Inception V3ê°€ ImageNetì„ ëª©í‘œë¡œ ì„¤ê³„ë˜ì–´ **ImageNetì— ë” ë§ì¶°ì ¸ ìˆì„ ê°€ëŠ¥ì„±**ìœ¼ë¡œ í•´ì„í•œë‹¤. ë°˜ëŒ€ë¡œ JFTì—ëŠ” ë‘ ëª¨ë¸ ëª¨ë‘ íŠ¹ë³„íˆ íŠœë‹ëœ êµ¬ì¡°ê°€ ì•„ë‹ˆë¯€ë¡œ, êµ¬ì¡° ìì²´ì˜ íš¨ìœ¨ ì°¨ì´ê°€ ë” ë“œëŸ¬ë‚  ìˆ˜ ìˆë‹¤ëŠ” ë…¼ë¦¬ë‹¤.

(Fig. 7: JFTì—ì„œì˜ í•™ìŠµ ê³¡ì„ (FC ì—†ìŒ))  
(Fig. 8: JFTì—ì„œì˜ í•™ìŠµ ê³¡ì„ (FC í¬í•¨))  

#### Table 2 í•´ì„: Head ìš©ëŸ‰ê³¼ Backbone êµ¬ì¡°ì˜ ìƒí˜¸ì‘ìš©
Table 2ëŠ” backbone êµ¬ì¡°(Inception V3 vs Xception)ë¿ ì•„ë‹ˆë¼, headì— fully-connected layerë¥¼ ì¶”ê°€í• ì§€ ì—¬ë¶€ê¹Œì§€ í•¨ê»˜ ë¹„êµí•œë‹¤. ì´ ì¡°í•© ë¹„êµëŠ” ë‹¤ìŒê³¼ ê°™ì€ í•´ì„ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.

1. No FC ì¡°ê±´ì—ì„œë„ Xceptionì´ ê°œì„ ì„ ë³´ì´ë¯€ë¡œ, ê°œì„ ì´ head ìš©ëŸ‰ ë•Œë¬¸ì´ ì•„ë‹ˆë¼ backbone ë³€í™˜ ìì²´ì™€ ê´€ë ¨ë¨ì„ ì‹œì‚¬í•œë‹¤.  
2. With FC ì¡°ê±´ì—ì„œë„ Xceptionì´ ê°œì„ ì„ ìœ ì§€í•˜ë¯€ë¡œ, headë¥¼ í‚¤ì›Œë„ backbone êµ¬ì¡° ì°¨ì´ê°€ ì‚¬ë¼ì§€ì§€ ì•ŠìŒì„ ë³´ì—¬ì¤€ë‹¤.  
3. FC ì¶”ê°€ ìì²´ëŠ” Inception V3ì—ì„œ 6.36â†’6.50, Xceptionì—ì„œ 6.70â†’6.78ë¡œ ì´ë“ì´ ìˆìœ¼ë‚˜, ê·¸ ì´ë“ì˜ í¬ê¸°ëŠ” Xception êµ¬ì¡°ì˜ ì´ë“ë³´ë‹¤ ì‘ë‹¤.  

ì¦‰, ë…¼ë¬¸ì´ ë§í•˜ëŠ” êµ¬ì¡°ì  íš¨ìœ¨ì€ head ì¡°ì •ìœ¼ë¡œ í¡ìˆ˜ë˜ëŠ” ì¢…ë¥˜ì˜ íš¨ê³¼ê°€ ì•„ë‹ˆë¼, backboneì˜ ì—°ì‚° ë¶„í•´ ë°©ì‹ì—ì„œ ë¹„ë¡¯ëœ íš¨ê³¼ë¡œ ì½ì„ ìˆ˜ ìˆë‹¤.

### ğŸ”¹ ëª¨ë¸ í¬ê¸°ì™€ ì†ë„: íŒŒë¼ë¯¸í„°ëŠ” ìœ ì‚¬, ì†ë„ëŠ” ê·¼ì†Œí•˜ê²Œ ëŠë¦¼
ë…¼ë¬¸ì€ ì„±ëŠ¥ ë¹„êµê°€ ë‹¨ì§€ ìˆ˜ì¹˜ í–¥ìƒì— ê·¸ì¹˜ì§€ ì•Šë„ë¡, Table 3ì—ì„œ í¬ê¸°/ì†ë„ë¥¼ í•¨ê»˜ ë³´ê³ í•œë‹¤. íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ImageNet(1000 classes, FC ì—†ìŒ) ê¸°ì¤€ì´ë©°, ì†ë„ëŠ” 60ê°œì˜ K80 GPUì—ì„œ synchronous SGDë¡œ ì¸¡ì •í•œ steps/secondë‹¤.

(Table 3: Model Size ë° Training Speed ë¹„êµ)  

| Model | Parameter Count | Steps/Second |
|---|---:|---:|
| Inception V3 | 23,626,728 | 31 |
| Xception | 22,855,952 | 28 |

ë…¼ë¬¸ì€ ë‘ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ë§¤ìš° ìœ ì‚¬í•˜ë¯€ë¡œ, ImageNet ë° JFTì—ì„œ ê´€ì¸¡ëœ ê°œì„ ì€ **ëª¨ë¸ ìš©ëŸ‰ ì¦ê°€ê°€ ì•„ë‹ˆë¼ íŒŒë¼ë¯¸í„° ì‚¬ìš©ì˜ íš¨ìœ¨**ì—ì„œ ë¹„ë¡¯ëœë‹¤ëŠ” ê²°ë¡ ì„ ê°•í™”í•œë‹¤. ë˜í•œ depthwise convolution êµ¬í˜„ ìµœì í™”ê°€ ì§„í–‰ë˜ë©´ Xceptionì´ ë” ë¹¨ë¼ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” ì „ë§ì„ ì œì‹œí•œë‹¤.

#### Table 3 í•´ì„: ì†ë„ ìˆ˜ì¹˜ì˜ ì½ëŠ” ë²•
Table 3ì—ì„œ steps/secondê°€ 31ì—ì„œ 28ë¡œ ê°ì†Œí•œ ê²ƒì€, Xceptionì´ ë” ì ì€ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§€ë©´ì„œë„ ë°˜ë“œì‹œ ë” ë¹ ë¥´ì§€ ì•Šì„ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤. ì´ëŠ” depthwise convolutionì´ ì´ë¡ ì ìœ¼ë¡œëŠ” ê³„ì‚°ëŸ‰ì„ ì¤„ì´ëŠ” ë°©í–¥ì´ì§€ë§Œ, ì‹¤ì œ GPU ì»¤ë„ì—ì„œëŠ”

- ì‘ì€ ì—°ì‚°ì´ ë§ì´ ìª¼ê°œì ¸ ë©”ëª¨ë¦¬ ì ‘ê·¼ ë¹„ì¤‘ì´ ì»¤ì§€ê±°ë‚˜  
- ì—°ì‚° ë³‘ë ¬í™”ê°€ ì •ê·œ convolutionë§Œí¼ íš¨ìœ¨ì ìœ¼ë¡œ ë˜ì§€ ì•Šê±°ë‚˜  
- í”„ë ˆì„ì›Œí¬ê°€ depthwise kernelì„ ì¶©ë¶„íˆ ìµœì í™”í•˜ì§€ ëª»í•˜ëŠ”  

ìƒí™©ì´ ë°œìƒí•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤. ë…¼ë¬¸ì´ ì´ ì ì„ í•œê³„ë¡œë„ ì–¸ê¸‰í•˜ëŠ” ê²ƒì€, ì„¤ê³„ ì•„ì´ë””ì–´ì˜ ê°€ì¹˜ê°€ ë‹¨ìˆœíˆ ì†ë„ ê°œì„ ì—ë§Œ ìˆì§€ ì•Šìœ¼ë©°, ì„±ëŠ¥ê³¼ ë‹¨ìˆœí™”ë¼ëŠ” ë‹¤ë¥¸ ì¶•ì˜ ì´ë“ë„ í•¨ê»˜ ë³¸ë‹¤ëŠ” íƒœë„ë¥¼ ë“œëŸ¬ë‚¸ë‹¤.

### ğŸ”¸ Residual Connection íš¨ê³¼: ìˆ˜ë ´ ì†ë„ ë° ìµœì¢… ì„±ëŠ¥ì— í•µì‹¬ì  ì—­í• 
ë…¼ë¬¸ì€ Xceptionì—ì„œ residual connectionì„ ì œê±°í•œ ë³€í˜•ì„ ImageNetì—ì„œ ë¹„êµí•´, residualì´ ìˆ˜ë ´ ì†ë„ì™€ ìµœì¢… ì„±ëŠ¥ ëª¨ë‘ì— ì¤‘ìš”í•˜ë‹¤ëŠ” ê²°ë¡ ì„ ì œì‹œí•œë‹¤.

(Fig. 9: Residual Connection ìœ ë¬´ì— ë”°ë¥¸ Training Profile ë¹„êµ)  

ì´ ì‹¤í—˜ì€ ë‹¨ìˆœí•œ ê²°ë¡ ì„ ë§í•´ì¤€ë‹¤. Xceptionì€ depthwise separable convolutionì„ ìŒ“ëŠ” ì„¤ê³„ë¥¼ ì·¨í•˜ì§€ë§Œ, ê·¸ ì„¤ê³„ë¥¼ ê¹Šê²Œ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” residualì´ ì‚¬ì‹¤ìƒ í•„ìˆ˜ì— ê°€ê¹ë‹¤.

#### Residual Ablationì˜ ë…¼ì¦ êµ¬ì¡°
Fig. 9ì˜ ë¹„êµëŠ” ë‹¨ìˆœíˆ ì„±ëŠ¥ì´ ì¢‹ì•„ì§„ë‹¤ëŠ” ìˆ˜ì¤€ì„ ë„˜ì–´ì„œ, Xceptionì´ë¼ëŠ” ì„¤ê³„ê°€ ë¬´ì—‡ì— ì˜ì¡´í•˜ëŠ”ì§€ë¥¼ ë¶„í•´í•´ ë³´ì—¬ì¤€ë‹¤. depthwise separable convolution ìì²´ëŠ” í‘œí˜„ì„ ë¶„í•´í•˜ëŠ” ì—°ì‚°ì´ì§€ë§Œ, ê·¸ ì—°ì‚°ì„ ìˆ˜ì‹­ ì¸µ ìŒ“ì•˜ì„ ë•Œ ìµœì í™”ê°€ ê°€ëŠ¥í•œì§€ëŠ” ë³„ê°œì˜ ë¬¸ì œë‹¤.

ë”°ë¼ì„œ ì´ ablationì€ ë‹¤ìŒì„ í™•ì¸í•˜ëŠ” ì—­í• ì„ í•œë‹¤.

1. Xceptionì˜ ì„±ëŠ¥ì´ depthwise separableì´ë¼ëŠ” ì—°ì‚° ë‹¨ì¼ ìš”ì†Œë§Œìœ¼ë¡œ ì„¤ëª…ë˜ì§€ ì•ŠìŒì„ í™•ì¸í•œë‹¤.  
2. ê¹Šì€ ë°˜ë³µ êµ¬ì¡°ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ìµœì í™” ì¥ì¹˜ë¡œì„œ residualì´ í•„ìˆ˜ì ì„ì„ ë³´ì—¬ì¤€ë‹¤.  

ë…¼ë¬¸ì´ Xceptionì„ VGG-Style stackì— ë¹„ìœ í•œ ë§¥ë½ê³¼ ì—°ê²°í•˜ë©´, VGGê°€ ê¹Šì´ë¥¼ í™•ë³´í•˜ëŠ” ë°©ì‹ì´ ë‹¨ìˆœ ë ˆì´ì–´ ëˆ„ì ì´ì—ˆë‹¤ë©´, Xceptionì€ ê·¸ ë‹¨ìˆœ ëˆ„ì ì„ residualë¡œ ë’·ë°›ì¹¨í•´ í•™ìŠµ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë§Œë“ ë‹¤ê³  ì •ë¦¬í•  ìˆ˜ ìˆë‹¤.

### ğŸ”¹ ì¤‘ê°„ Activation íš¨ê³¼: Depthwiseâ€“Pointwise ì‚¬ì´ ReLU/ELUì˜ ë¶€ì •ì  ì˜í–¥
ë…¼ë¬¸ì€ depthwise separable convolutionê³¼ Inception ëª¨ë“ˆì˜ ìœ ì‚¬ì„±ì´ ì¤‘ê°„ activation í¬í•¨ì„ ì•”ì‹œí•  ìˆ˜ ìˆìŒì„ ì–¸ê¸‰í•œë‹¤. ê·¸ëŸ¬ë‚˜ ì‹¤ì œë¡œëŠ” ReLU ë˜ëŠ” ELUë¥¼ ì¤‘ê°„ì— ë„£ëŠ” ê²ƒì´ ì˜¤íˆë ¤ ì„±ëŠ¥ì„ í•´ì¹œë‹¤ê³  ë³´ê³ í•œë‹¤. ì¦‰, **ì¤‘ê°„ activationì´ ì—†ëŠ” ì„¤ì •ì´ ë” ë¹ ë¥¸ ìˆ˜ë ´ê³¼ ë” ì¢‹ì€ ìµœì¢… ì„±ëŠ¥**ì„ ë§Œë“ ë‹¤ëŠ” ê²°ê³¼ë¥¼ ì œì‹œí•œë‹¤.

(Fig. 10: Depthwiseâ€“Pointwise ì‚¬ì´ Activation ì¢…ë¥˜ë³„ Training Profile ë¹„êµ)  

ë…¼ë¬¸ì€ ì´ ê²°ê³¼ë¥¼ ì¤‘ê°„ feature spaceì˜ ê¹Šì´ê°€ ì–•ì„ìˆ˜ë¡ non-linearityê°€ ì •ë³´ ì†ì‹¤ì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤ëŠ” ì§ê´€ìœ¼ë¡œ ì—°ê²°í•œë‹¤.

#### Intermediate Activation ì‹¤í—˜ì˜ ì§ê´€ì  í•´ì„
Depthwiseâ€“Pointwise ì‚¬ì´ì˜ activationì€ ì±„ë„ í˜¼í•© ì´ì „ì— ì ìš©ëœë‹¤ëŠ” ì ì—ì„œ íŠ¹ë³„í•˜ë‹¤. depthwise ë‹¨ê³„ëŠ” ì±„ë„ë³„ë¡œ ë…ë¦½ì ì¸ ê³µê°„ ë³€í™˜ì´ê¸° ë•Œë¬¸ì—, ì´ ë‹¨ê³„ì˜ ì¶œë ¥ì€ ì±„ë„ ê°„ ìƒí˜¸ì‘ìš© ì—†ì´ ë§Œë“¤ì–´ì§„ë‹¤. ì´ë•Œ ReLU ê°™ì€ ë¹„ì„ í˜•ì´ ë¨¼ì € ì ìš©ë˜ë©´

1. ì±„ë„ë³„ ê³µê°„ íŠ¹ì§•ì—ì„œ ìŒìˆ˜ ì„±ë¶„ì´ ì†Œê±°ë˜ê³   
2. ì´í›„ pointwiseì—ì„œ ì±„ë„ë“¤ì„ ì„ì–´ ë³µí•©ì ì¸ ì¡°í•©ì„ ë§Œë“¤ ê¸°íšŒê°€ ì¤„ì–´ë“¤ë©°  
3. ê²°ê³¼ì ìœ¼ë¡œ í‘œí˜„ ê³µê°„ì´ ë¶ˆí•„ìš”í•˜ê²Œ ì œí•œë  ìˆ˜ ìˆë‹¤  

ëŠ” ë°©í–¥ì˜ ì„¤ëª…ì´ ê°€ëŠ¥í•˜ë‹¤. ë°˜ëŒ€ë¡œ activationì„ pointwise ì´í›„ë¡œ ë¯¸ë£¨ë©´, ì±„ë„ í˜¼í•©ì´ ë¨¼ì € ì¼ì–´ë‚œ ë’¤ ë¹„ì„ í˜•ì´ ì ìš©ë˜ë¯€ë¡œ ì±„ë„ ì¡°í•©ì˜ í‘œí˜„ë ¥ì´ ë” ë„“ê²Œ ìœ ì§€ë  ìˆ˜ ìˆë‹¤.

ì´ ì‹¤í—˜ì€ Xceptionì´ ë‹¨ì§€ ì—°ì‚°ì„ ë¶„í•´í•œë‹¤ëŠ” ì£¼ì¥ì— ê·¸ì¹˜ì§€ ì•Šê³ , ë¶„í•´ëœ ì—°ì‚°ë“¤ ì‚¬ì´ì— ë¹„ì„ í˜•ì„ ì–´ë””ì— ë‘˜ì§€ê¹Œì§€ í¬í•¨í•´ ì„¤ê³„ê°€ ì™„ì„±ëœë‹¤ëŠ” ì ì„ ê°•ì¡°í•˜ëŠ” ì—­í• ì„ í•œë‹¤.

## 5ï¸âƒ£ Future Directions

### ğŸ”¸ ì—°ì†ì²´ì˜ ì¤‘ê°„ ì§€ì  íƒìƒ‰: Depthwise Separableì´ ìµœì„ ì´ë¼ëŠ” ë³´ì¥ì€ ì—†ìŒ
ë…¼ë¬¸ì€ ì •ê·œ convolutionê³¼ depthwise separable convolution ì‚¬ì´ì˜ ì´ì‚° ìŠ¤í™íŠ¸ëŸ¼ì„ ë‹¤ì‹œ ìƒê¸°ì‹œí‚¤ë©°, Xceptionì´ íƒí•œ ê·¹ë‹¨ì´ ìµœì ì´ë¼ëŠ” ë³´ì¥ì€ ì—†ë‹¤ê³  ë§í•œë‹¤. ì˜¤íˆë ¤ Inceptionê³¼ depthwise separable ì‚¬ì´ì˜ ì¤‘ê°„ ì§€ì ì— ì¶”ê°€ ì´ì ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” í›„ì† ì—°êµ¬ ê³¼ì œë¡œ ë‚¨ê¸´ë‹¤.

ì´ ì„¹ì…˜ì€ Xceptionì´ ë‹¨ì§€ íŠ¹ì • ì•„í‚¤í…ì²˜ë¥¼ ì œì‹œí•˜ëŠ” ê²ƒì—ì„œ ëë‚˜ì§€ ì•Šê³ , **ì„¤ê³„ ê³µê°„ ìì²´ë¥¼ ì¬ì •ì˜**í•˜ë ¤ëŠ” ì‹œë„ë¥¼ í¬í•¨í•œë‹¤ëŠ” ì ì—ì„œ ì¤‘ìš”í•˜ë‹¤.

#### Intermediate Group Settingì˜ íƒìƒ‰ ê´€ì 
ë…¼ë¬¸ì´ ë§í•˜ëŠ” ì¤‘ê°„ ì§€ì ì€ ê²°êµ­ group count $g$ë¥¼ ì–´ë–»ê²Œ ë‘ëŠëƒì˜ ë¬¸ì œë¡œ êµ¬ì²´í™”í•  ìˆ˜ ìˆë‹¤. $g$ê°€ ì¦ê°€í•˜ë©´ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ì¤„ì–´ë“¤ì§€ë§Œ, ì±„ë„ í˜¼í•©ì´ ì œí•œëœë‹¤. ë”°ë¼ì„œ ì¤‘ê°„ ì§€ì  íƒìƒ‰ì€

- ì±„ë„ í˜¼í•©ì„ ì–¼ë§ˆë‚˜ ìì£¼, ì–´ë–¤ ìœ„ì¹˜ì—ì„œ ìˆ˜í–‰í• ì§€  
- spatial ë³€í™˜ì´ ì±„ë„ ê°„ ìƒí˜¸ì‘ìš©ì— ì–¼ë§ˆë‚˜ ì˜ì¡´í•˜ëŠ”ì§€  
- ë¶„í•´ë¡œ ì¸í•œ íš¨ìœ¨ ì´ë“ê³¼ í‘œí˜„ë ¥ ì†ì‹¤ì´ ì–´ë””ì„œ ê· í˜•ì„ ì´ë£¨ëŠ”ì§€  

ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì‚´í´ë³´ëŠ” ë¬¸ì œë¡œ ë°”ë€ë‹¤. Xceptionì˜ ì£¼ì¥ì²˜ëŸ¼ Inceptionì´ ì—°ì†ì²´ì˜ ì¤‘ê°„ ì§€ì  ì¤‘ í•˜ë‚˜ë¼ë©´, Inceptionì˜ íŠ¹ì • ë¶„ê¸° ì„¤ê³„ê°€ ìš°ì—°íˆ ì¢‹ì€ ê²ƒì´ ì•„ë‹ˆë¼, ë” ì¼ë°˜ì ì¸ $g$-ìŠ¤í™íŠ¸ëŸ¼ ìƒì˜ í•œ ì„ íƒìœ¼ë¡œ ì´í•´ë  ìˆ˜ ìˆë‹¤.

#### Hardware Efficiency ê´€ì ì˜ í›„ì† ê³¼ì œ
Table 3ì˜ ì†ë„ ê²°ê³¼ëŠ” ì„¤ê³„ ê³µê°„ íƒìƒ‰ì´ ì •í™•ë„ë§Œìœ¼ë¡œ ëë‚˜ì§€ ì•ŠìŒì„ ì‹œì‚¬í•œë‹¤. ê°™ì€ FLOPsë¼ë„ ì‹¤ì œ throughputì€ ì»¤ë„ ìµœì í™” ìˆ˜ì¤€ì— í¬ê²Œ ì˜ì¡´í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, $g$ë¥¼ ì¡°ì •í•˜ëŠ” íƒìƒ‰ì€

- ìˆ˜í•™ì  íš¨ìœ¨(FLOPs, params)  
- ì‹œìŠ¤í…œ íš¨ìœ¨(ì»¤ë„ íš¨ìœ¨, ë©”ëª¨ë¦¬ ì ‘ê·¼ íŒ¨í„´)  

ì„ í•¨ê»˜ ê³ ë ¤í•´ì•¼ í•œë‹¤. ë…¼ë¬¸ì´ ë¯¸ë˜ ê³¼ì œë¥¼ ë‚¨ê¸´ ì‹œì ì—ëŠ” depthwise kernel ìµœì í™”ê°€ ì¶©ë¶„íˆ ì„±ìˆ™í•˜ì§€ ì•Šì•˜ìŒì„ ê°ì•ˆí•˜ë©´, ì¤‘ê°„ group settingì´ ì˜¤íˆë ¤ ë” ë†’ì€ ì‹¤ì œ ì†ë„ë¥¼ ë‚¼ ê°€ëŠ¥ì„±ë„ ë…¼ë¦¬ì ìœ¼ë¡œ ë°°ì œí•  ìˆ˜ ì—†ë‹¤.

## 6ï¸âƒ£ Conclusions

### ğŸ”¹ ê²°ë¡  ìš”ì•½: Inception ëŒ€ì²´ë¡œì„œì˜ Depthwise Separable Stack
ë…¼ë¬¸ ê²°ë¡ ì€ ë‹¤ìŒ íë¦„ìœ¼ë¡œ ì •ë¦¬ëœë‹¤.

1. ì •ê·œ convolutionê³¼ depthwise separable convolutionì€ ìŠ¤í™íŠ¸ëŸ¼ì˜ ì–‘ ëì´ë©°, Inceptionì€ ê·¸ ì¤‘ê°„ ì§€ì ì´ë‹¤.  
2. ì´ ê´€ì°°ë¡œë¶€í„° Inception ëª¨ë“ˆì„ depthwise separable convolutionìœ¼ë¡œ ì¹˜í™˜í•œ Xceptionì„ ì œì•ˆí•œë‹¤.  
3. Xceptionì€ Inception V3ì™€ ìœ ì‚¬í•œ íŒŒë¼ë¯¸í„° ìˆ˜ì—ì„œ ImageNetì—ì„œëŠ” ì†Œí­, JFTì—ì„œëŠ” í° ì„±ëŠ¥ í–¥ìƒì„ ë³´ì¸ë‹¤.  
4. depthwise separable convolutionì€ Inceptionì´ ê°€ì§„ ì„±ì§ˆì„ ìœ ì§€í•˜ë©´ì„œë„ ì‚¬ìš©ì´ ë‹¨ìˆœí•˜ë¯€ë¡œ, í–¥í›„ ì•„í‚¤í…ì²˜ ì„¤ê³„ì˜ ì¤‘ìš”í•œ êµ¬ì„± ìš”ì†Œê°€ ë  ìˆ˜ ìˆë‹¤.  

#### ê²°ë¡ ì˜ ë…¼ì¦ ë°©ì‹: ê°€ì„¤, ì„¤ê³„, ì‹¤í—˜, ë¶„í•´
Xception ê²°ë¡ ì´ ì¸ìƒì ì¸ ì´ìœ ëŠ”, ë‹¨ìˆœíˆ ìƒˆë¡œìš´ ë¸”ë¡ì„ ì œì•ˆí•˜ê³  ëë‚˜ëŠ” êµ¬ì¡°ê°€ ì•„ë‹ˆë¼ ë…¼ì¦ íë¦„ì´ ë¹„êµì  ëª…í™•í•˜ê¸° ë•Œë¬¸ì´ë‹¤.

1. ê°€ì„¤: ì±„ë„ ìƒê´€ê´€ê³„ì™€ ê³µê°„ ìƒê´€ê´€ê³„ëŠ” ë¶„ë¦¬ ê°€ëŠ¥í•˜ë‹¤ëŠ” Inception ê°€ì„¤ì˜ í™•ì¥  
2. ì„¤ê³„: ê·¸ ë¶„ë¦¬ë¥¼ ê·¹ë‹¨ìœ¼ë¡œ ë°€ì–´ depthwise separable stackì„ êµ¬ì„±  
3. ì‹¤í—˜: ImageNetê³¼ JFTì—ì„œ ìŠ¤ì¼€ì¼ì„ ë§ì¶˜ ë¹„êµë¡œ êµ¬ì¡°ì  ì°¨ì´ë¥¼ ê´€ì°°  
4. ë¶„í•´: residual ë° intermediate activationì„ ë¶„ë¦¬ ì‹¤í—˜ìœ¼ë¡œ ê²€ì¦  

íŠ¹íˆ 4ë‹¨ê³„ì˜ ë¶„í•´ ì‹¤í—˜ì€, ì„¤ê³„ê°€ ë‹¨ì¼ ì•„ì´ë””ì–´ì˜ ê²°ê³¼ê°€ ì•„ë‹ˆë¼ ì—¬ëŸ¬ ì„ íƒì˜ ê²°í•©ì„ì„ ë³´ì—¬ì£¼ë©°, ë…ìê°€ í›„ì† ì„¤ê³„ë¥¼ í•  ë•Œ ë¬´ì—‡ì„ ê³ ì •í•˜ê³  ë¬´ì—‡ì„ ë°”ê¿”ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•œ íŒíŠ¸ë¥¼ ì œê³µí•œë‹¤.

## ğŸ’¡ í•´ë‹¹ ë…¼ë¬¸ì˜ ì‹œì‚¬ì ê³¼ í•œê³„ í˜¹ì€ ì˜ì˜
Xceptionì˜ ì˜ì˜ëŠ” Inceptionì„ ë‹¨ì§€ ì˜ ì„¤ê³„ëœ ëª¨ë“ˆë¡œ ë³´ì§€ ì•Šê³ , **ì—°ì‚° ë¶„í•´ì˜ ê´€ì **ì—ì„œ ì¬ì •ì˜í–ˆë‹¤ëŠ” ë° ìˆë‹¤. Inceptionì´ ì±„ë„Â·ê³µê°„ ìƒê´€ê´€ê³„ì˜ ë¶€ë¶„ì  ë¶„í•´ë¥¼ ìˆ˜í–‰í•œë‹¤ë©´, Xceptionì€ ì´ë¥¼ ê·¹ë‹¨ìœ¼ë¡œ ë°€ì–´ë¶™ì—¬ ì™„ì „ ë¶„í•´ì— ê°€ê¹Œìš´ í˜•íƒœë¥¼ ì·¨í•œë‹¤. ì´ ë•ë¶„ì— ì•„í‚¤í…ì²˜ëŠ” ì˜¤íˆë ¤ ë‹¨ìˆœí•´ì§€ê³ , ê¹Šì€ ë°˜ë³µê³¼ residualì„ ê²°í•©í•œ ì„ í˜• ìŠ¤íƒ í˜•íƒœë¡œ ì •ë¦¬ëœë‹¤.

ì‹¤í—˜ì ìœ¼ë¡œëŠ” íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ìœ ì‚¬í•œ ì¡°ê±´ì—ì„œ ê°œì„ ì„ ë³´ì´ë©°, íŠ¹íˆ ë” í° ë°ì´í„°ì—ì„œ ê°œì„  í­ì´ ì»¤ì§€ëŠ” ì ì´ êµ¬ì¡°ì  íš¨ìœ¨ ì£¼ì¥ì— í˜ì„ ì‹£ëŠ”ë‹¤. ë˜í•œ ì¤‘ê°„ activationì˜ ìœ ë¬´, residualì˜ ìœ ë¬´ë¥¼ ë³„ë„ ì‹¤í—˜ìœ¼ë¡œ ë¶„í•´í•´, ì„¤ê³„ ì„ íƒì˜ í•„ìš”ì„±ì„ ë…¼ì¦í•˜ë ¤ê³  í•œë‹¤.

í•œê³„ë¡œëŠ” depthwise convolutionì˜ êµ¬í˜„ íš¨ìœ¨ì´ í•˜ë“œì›¨ì–´/í”„ë ˆì„ì›Œí¬ ìµœì í™”ì— ë¯¼ê°í•  ìˆ˜ ìˆê³ , ì‹¤ì œë¡œ ë…¼ë¬¸ì—ì„œë„ Xceptionì´ ë‹¹ì‹œ ê¸°ì¤€ìœ¼ë¡œ ì•½ê°„ ëŠë¦¬ë‹¤ê³  ë³´ê³ í•œë‹¤. ë˜í•œ ë…¼ë¬¸ ìŠ¤ìŠ¤ë¡œë„ depthwise separableì´ ìŠ¤í™íŠ¸ëŸ¼ì˜ ìµœì ì ì´ë¼ëŠ” ë³´ì¥ì€ ì—†ë‹¤ê³  ì¸ì •í•˜ë©°, ì¤‘ê°„ ì§€ì  íƒìƒ‰ì„ ë¯¸ë˜ ê³¼ì œë¡œ ë‚¨ê¸´ë‹¤.

#### ì„¤ê³„ í•´ì„ì˜ ì˜ì˜: Module Engineeringì—ì„œ Operator Factorizationìœ¼ë¡œ
Inception ê³„ì—´ì€ ì¢…ì¢… ëª¨ë“ˆ ì„¤ê³„ê°€ ê²½í—˜ì  ë ˆì‹œí”¼ì²˜ëŸ¼ ë³´ì´ê¸° ì‰½ë‹¤. Xceptionì€ ì´ë¥¼ ì±„ë„/ê³µê°„ ìƒê´€ê´€ê³„ ë¶„í•´ë¼ëŠ” ê´€ì ìœ¼ë¡œ ì¬í•´ì„í•¨ìœ¼ë¡œì¨, ëª¨ë“ˆ ì„¤ê³„ê°€ ì„ì˜ì  ì„ íƒì´ ì•„ë‹ˆë¼ ì—°ì‚° êµ¬ì¡°ì˜ í•œ ì ìœ¼ë¡œ ì„¤ëª…ë  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤. ì´ëŠ” í›„ì† ì„¤ê³„ì—ì„œ

- ë¶„ê¸° ìˆ˜ë‚˜ tower êµ¬ì„± ê°™ì€ í‘œë©´ì  ì„ íƒë³´ë‹¤  
- ì±„ë„ í˜¼í•©ê³¼ ê³µê°„ ë³€í™˜ì˜ ê²°í•© ì •ë„ë¥¼ ë¨¼ì € ê²°ì •í•˜ê³   
- ê·¸ ê²°ì •ì„ êµ¬í˜„ ê°€ëŠ¥í•œ ë¸”ë¡ í˜•íƒœë¡œ ë‚´ë¦¬ëŠ”  

ë°©í–¥ì˜ ì‚¬ê³ ë¥¼ ìœ ë„í•œë‹¤ëŠ” ì ì—ì„œ ì˜ë¯¸ê°€ ìˆë‹¤.

#### ì‹¤í—˜ ì„¤ê³„ì˜ ì˜ì˜: ë°ì´í„° ê·œëª¨ì— ë”°ë¥¸ êµ¬ì¡°ì˜ ì¼ë°˜ì„± ì ê²€
ë…¼ë¬¸ì´ JFTë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ê²ƒì€, ëª¨ë¸ì´ ImageNetì— íŠœë‹ëœ ë ˆì‹œí”¼ì˜ ì‚°ë¬¼ì¸ì§€ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•¨ì´ë‹¤. JFTì—ì„œì˜ ë” í° ê°œì„ ì€ Xception êµ¬ì¡°ê°€ íŠ¹ì • ë°ì´í„°ì…‹ì˜ íŠ¹ìˆ˜ì„±ì— ëœ ì˜ì¡´í•˜ê³ , ë” ì¼ë°˜ì ì¸ êµ¬ì¡°ì  íš¨ìœ¨ì„ ì œê³µí•  ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•œë‹¤.

ë‹¤ë§Œ JFT ì‹¤í—˜ì´ ì™„ì „ ìˆ˜ë ´ê¹Œì§€ í•™ìŠµëœ ê²ƒì´ ì•„ë‹ˆë¼ëŠ” ì ì€, ê²°ê³¼ í•´ì„ì—ì„œ í•­ìƒ ì—¼ë‘ì— ë‘ì–´ì•¼ í•œë‹¤. ì´ ê²½ìš° í•™ìŠµ ê³¡ì„ (Fig. 7â€“8)ì˜ í˜•íƒœê°€ ì¤‘ìš”í•´ì§€ë©°, ì´ˆê¸° êµ¬ê°„ì˜ ìˆ˜ë ´ ì†ë„ ì°¨ì´ê°€ ë³´ê³ ëœ MAP@100 ì°¨ì´ë¡œ ì´ì–´ì¡Œì„ ê°€ëŠ¥ì„±ë„ ì¶©ë¶„íˆ ìˆë‹¤.

---

## ğŸ‘¨ğŸ»â€ğŸ’» Xception Lucid êµ¬í˜„
Lucid êµ¬í˜„ì€ `lucid/models/imgclf/xception.py`ì— Xceptionì„ ì§ì ‘ êµ¬í˜„í•˜ê³  ìˆë‹¤. êµ¬í˜„ í•´ì„¤ì€ ë‹¤ìŒ ìˆœì„œë¡œ ì§„í–‰í•œë‹¤.

1. `ConvBNReLU2d`ê°€ Stemì—ì„œ ìˆ˜í–‰í•˜ëŠ” ê²°í•© ì—°ì‚°(`lucid/nn/fused.py`)  
2. Depthwise Separable Convolutionì´ Lucidì—ì„œ ì–´ë–¤ ì—°ì‚°ìœ¼ë¡œ êµ¬í˜„ë˜ëŠ”ì§€(`lucid/nn/fused.py`)  
3. Xceptionì˜ í•µì‹¬ ë¸”ë¡ì¸ `_Block`ì˜ êµ¬ì„±ê³¼ residual ê²½ë¡œ  
4. `Xception` í´ë˜ìŠ¤ì˜ Entry/Middle/Exit ëŒ€ì‘ êµ¬ì¡°  
5. ëª¨ë¸ ë“±ë¡ í•¨ìˆ˜ `xception`  

### 0ï¸âƒ£ `nn.ConvBNReLU2d`: Stemì˜ Convolution + Batch Normalization + ReLU ê²°í•©
`Xception` í´ë˜ìŠ¤ì˜ stemì€ `ConvBNReLU2d`ë¥¼ ì‚¬ìš©í•´ ì´ˆê¸° 3Ã—3 convolution ë‘ ê°œë¥¼ êµ¬ì„±í•œë‹¤. Lucid êµ¬í˜„ì—ì„œ `ConvBNReLU2d`ëŠ” `lucid/nn/fused.py`ì˜ `_ConvBNReLU`ë¥¼ 2Dë¡œ íŠ¹ìˆ˜í™”í•œ í´ë˜ìŠ¤ë‹¤.

```python
class _ConvBNReLU(nn.Module):
    D: ClassVar[int | None] = None

    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size: int | tuple[int, ...],
        stride: int | tuple[int, ...] = 1,
        padding: _PaddingStr | int | tuple[int, ...] = 0,
        dilation: int | tuple[int, ...] = 1,
        groups: int = 1,
        conv_bias: bool = True,
        eps: float = 1e-5,
        momentum: float | None = 0.1,
        bn_affine: bool = True,
        track_running_stats: bool = True,
    ) -> None:
        super().__init__()
        if self.D is None:
            raise ValueError("Must specify 'D' value.")

        self.conv: nn.Module = _Conv[self.D - 1](
            in_channels,
            out_channels,
            kernel_size,
            stride,
            padding,
            dilation,
            groups,
            conv_bias,
        )
        self.bn: nn.Module = _BN[self.D - 1](
            out_channels, eps, momentum, bn_affine, track_running_stats
        )
        self.relu = nn.ReLU()

    def forward(self, input_: Tensor) -> Tensor:
        return self.relu(self.bn(self.conv(input_)))


class ConvBNReLU2d(_ConvBNReLU):
    D: ClassVar[int] = 2
```

ì´ ëª¨ë“ˆì€ `Conv2d â†’ BN â†’ ReLU` íŒ¨í„´ì„ í•˜ë‚˜ì˜ í´ë˜ìŠ¤ë¡œ ë¬¶ëŠ”ë‹¤. ë…¼ë¬¸ Fig. 5ì—ì„œë„ convolution ë’¤ì— batch normalizationì´ ë¶™ëŠ” íŒ¨í„´ì´ ë°˜ë³µë˜ë©°, Lucid êµ¬í˜„ì€ ì´ ë°˜ë³µì„ `ConvBNReLU2d`ì™€ `_Block` ë‚´ë¶€ì˜ BN ë°°ì¹˜ë¡œ êµ¬í˜„í•œë‹¤.

### 1ï¸âƒ£ `nn.DepthSeparableConv2d`: Depthwise ì´í›„ Pointwise
Xceptionì˜ í•µì‹¬ ì—°ì‚°ì€ `nn.DepthSeparableConv2d`ë‹¤. Lucidì—ì„œëŠ” `lucid/nn/fused.py`ì˜ `_DepthSeparableConv`ë¥¼ í†µí•´ depthwiseì™€ pointwiseë¥¼ ë‹¤ìŒì²˜ëŸ¼ êµ¬í˜„í•œë‹¤.

```python
class _DepthSeparableConv(nn.Module):
    D: ClassVar[int | None] = None

    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size: int | tuple[int, ...],
        stride: int | tuple[int, ...] = 1,
        padding: _PaddingStr | int | tuple[int, ...] = 0,
        dilation: int | tuple[int, ...] = 1,
        bias: bool = True,
    ) -> None:
        super().__init__()
        if self.D is None:
            raise ValueError("Must specify 'D' value.")

        self.depthwise = _Conv[self.D - 1](
            in_channels,
            in_channels,
            kernel_size,
            stride,
            padding,
            dilation,
            groups=in_channels,
            bias=bias,
        )
        self.pointwise = _Conv[self.D - 1](
            in_channels,
            out_channels,
            kernel_size=1,
            bias=bias,
        )
        self.reversed = reversed

    def forward(self, input_: Tensor) -> Tensor:
        return self.pointwise(self.depthwise(input_))
```

ì—¬ê¸°ì„œ ë…¼ë¬¸ ì •ì˜ì™€ 1:1ë¡œ ëŒ€ì‘ë˜ëŠ” í¬ì¸íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

- depthwise ë‹¨ê³„ëŠ” `groups=in_channels`ë¡œ ì„¤ì •ëœ convolutionì´ë©°, **ì±„ë„ë³„ ë…ë¦½ ê³µê°„ convolution**ì„ êµ¬í˜„í•œë‹¤.  
- pointwise ë‹¨ê³„ëŠ” `kernel_size=1`ì¸ convolutionì´ë©°, **ì±„ë„ ê³µê°„ ì‚¬ìƒ(í˜¼í•©)**ì„ êµ¬í˜„í•œë‹¤.  
- forwardëŠ” `depthwise â†’ pointwise` ìˆœì„œì´ë©°, ë…¼ë¬¸ì´ ë§í•œ ì¼ë°˜ì  êµ¬í˜„ ìˆœì„œì™€ ë™ì¼í•˜ë‹¤.  

ë…¼ë¬¸ì—ì„œ ë…¼ì˜í•œ ì¤‘ê°„ activationì˜ ë¶€ì¬ëŠ” Lucid êµ¬í˜„ì—ì„œë„ ê·¸ëŒ€ë¡œë‹¤. `DepthSeparableConv2d` ë‚´ë¶€ì—ëŠ” ReLU/ELUê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©°, activationì€ ë¸”ë¡ ë‹¨ìœ„ì—ì„œ ì™¸ë¶€ì ìœ¼ë¡œ ë°°ì¹˜ëœë‹¤.

#### `self.reversed` í•„ë“œì˜ ì„±ê²©
`_DepthSeparableConv`ì— ìˆëŠ” `self.reversed = reversed`ëŠ” ì´ í´ë˜ìŠ¤ì˜ forward ê²½ë¡œì—ì„œ ì§ì ‘ ì‚¬ìš©ë˜ì§€ëŠ” ì•ŠëŠ”ë‹¤. ë”°ë¼ì„œ Xception êµ¬í˜„ì„ ì´í•´í•˜ëŠ” ê´€ì ì—ì„œëŠ” í•µì‹¬ ìš”ì†Œê°€ ì•„ë‹ˆë©°, ì—°ì‚° ì •ì˜ì™€ë„ ë¬´ê´€í•˜ë‹¤. ë‹¤ë§Œ ì½”ë“œê°€ ì‹¤ì œë¡œ í¬í•¨í•˜ê³  ìˆëŠ” í•„ë“œì´ë¯€ë¡œ, Lucid êµ¬í˜„ê³¼ ë…¼ë¬¸ ì •ì˜ê°€ ë§Œë‚˜ëŠ” ì§€ì ì„ í™•ì¸í•  ë•ŒëŠ” depthwise/pointwise ë‘ convì™€ ê·¸ ìˆœì„œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë³´ë©´ ì¶©ë¶„í•˜ë‹¤.

### 2ï¸âƒ£ `_Block`: Depthwise Separable Stackê³¼ Residual Skip
`lucid/models/imgclf/xception.py`ì˜ `_Block`ì€ Xceptionì˜ ëª¨ë“ˆ ë‹¨ìœ„ë¥¼ êµ¬í˜„í•œë‹¤. ì…ë ¥/ì¶œë ¥ ì±„ë„ê³¼ ë°˜ë³µ íšŸìˆ˜(`reps`), ë‹¤ìš´ìƒ˜í”Œë§(`stride`) ë° ë¸”ë¡ ë‚´ë¶€ì˜ ë°°ì¹˜ ê·œì¹™ì„ ì¸ìë¡œ ë°›ëŠ”ë‹¤.

#### 2.1 Skip ê²½ë¡œ ì •ì˜: ì±„ë„/í•´ìƒë„ ë¶ˆì¼ì¹˜ ì‹œ 1Ã—1 Projection
`_Block.__init__`ì€ `out_channels != in_channels` ë˜ëŠ” `stride != 1`ì´ë©´ skip ê²½ë¡œì— 1Ã—1 convolutionê³¼ BNì„ ë‘”ë‹¤.

```python
if out_channels != in_channels or stride != 1:
    self.skip = nn.Conv2d(
        in_channels, out_channels, kernel_size=1, stride=stride, bias=False
    )
    self.skipbn = nn.BatchNorm2d(out_channels)
else:
    self.skip = None
```

ì´ëŠ” ResNetì˜ projection shortcutê³¼ ë™ì¼í•œ ì—­í• ì„ í•œë‹¤. ë‹¤ìš´ìƒ˜í”Œë§ì´ ìˆê±°ë‚˜ ì±„ë„ ìˆ˜ê°€ ë°”ë€Œë©´, skip ê²½ë¡œë¥¼ í†µí•´ shapeì„ ë§ì¶˜ ë’¤ ë”í•œë‹¤.

#### 2.2 Main ê²½ë¡œ êµ¬ì„±: `reps`ì— ë”°ë¥¸ ë°˜ë³µ DepthSeparableConv2d
`rep` ë¦¬ìŠ¤íŠ¸ë¥¼ êµ¬ì„±í•˜ëŠ” í•µì‹¬ì€ ë‘ ê°œì˜ í”Œë˜ê·¸ë‹¤.

- `start_with_relu`: ë¸”ë¡ ì²« ì—°ì‚°ì—ì„œ ReLUë¥¼ ë‘˜ì§€ ì—¬ë¶€  
- `grow_first`: ì±„ë„ í™•ì¥ì„ ë¸”ë¡ ì´ˆë°˜ì— ë‘˜ì§€ ì—¬ë¶€  

`grow_first=True`ì´ë©´, ì²« ë²ˆì§¸ separable convì—ì„œ `in_channels â†’ out_channels`ë¡œ ì±„ë„ì„ ë¨¼ì € í™•ì¥í•˜ê³ (`channels = out_channels`ë¡œ ê°±ì‹ ), ì´í›„ `reps-1`ë²ˆì€ `channels â†’ channels` ë°˜ë³µì„ ìˆ˜í–‰í•œë‹¤.

```python
if grow_first:
    rep.append(nn.ReLU())
    rep.append(
        nn.DepthSeparableConv2d(
            in_channels, out_channels, kernel_size=3, padding=1, bias=False
        )
    )
    rep.append(nn.BatchNorm2d(out_channels))
    channels = out_channels

for i in range(reps - 1):
    rep.append(nn.ReLU())
    rep.append(
        nn.DepthSeparableConv2d(
            channels, channels, kernel_size=3, padding=1, bias=False
        )
    )
    rep.append(nn.BatchNorm2d(channels))
```

ë°˜ëŒ€ë¡œ `grow_first=False`ì´ë©´, ë°˜ë³µì„ ìˆ˜í–‰í•œ ë’¤ ë¸”ë¡ ë§ˆì§€ë§‰ì—ì„œ `in_channels â†’ out_channels`ë¡œ ì±„ë„ì„ ë§ì¶”ëŠ” í˜•íƒœë¡œ êµ¬ì„±ëœë‹¤.

```python
if not grow_first:
    rep.append(nn.ReLU())
    rep.append(
        nn.DepthSeparableConv2d(
            in_channels, out_channels, kernel_size=3, padding=1, bias=False
        )
    )
    rep.append(nn.BatchNorm2d(out_channels))
```

#### 2.3 ReLU ì‹œì‘ ì¡°ê±´ê³¼ Downsampling
`start_with_relu`ì— ë”°ë¼ ì²« ReLUë¥¼ ì œê±°í•˜ê±°ë‚˜ ìœ ì§€í•œë‹¤.

```python
if not start_with_relu:
    rep = rep[1:]
else:
    rep[0] = nn.ReLU()
```

ë˜í•œ `stride != 1`ì´ë©´ ë¸”ë¡ ëì— MaxPoolì„ ì¶”ê°€í•œë‹¤.

```python
if stride != 1:
    rep.append(nn.MaxPool2d(kernel_size=3, stride=stride, padding=1))
```

ì´ êµ¬ì„±ì€ ë…¼ë¬¸ Fig. 5ì—ì„œ entry/exit flowì—ì„œ ë‹¤ìš´ìƒ˜í”Œë§ì´ ë“¤ì–´ê°€ëŠ” ëª¨ë“ˆë“¤ì˜ ì—­í• ê³¼ ëŒ€ì‘ëœë‹¤.

#### 2.4 Forward: Main ê²½ë¡œì™€ Skip ê²½ë¡œì˜ í•©
`_Block.forward`ëŠ” main ê²½ë¡œë¥¼ í†µê³¼í•œ ë’¤, skipì„ ë”í•œë‹¤.

```python
def forward(self, x: Tensor) -> Tensor:
    out = self.rep(x)

    if self.skip is not None:
        skip = self.skip(x)
        skip = self.skipbn(skip)
    else:
        skip = x

    out += skip
    return out
```

ì¦‰ Lucidì˜ `_Block`ì€ ë…¼ë¬¸ì´ ê°•ì¡°í•œ residual connectionì„ ëª¨ë“ˆ ë‹¨ìœ„ë¡œ ê°•ì œí•˜ëŠ” êµ¬í˜„ì´ë‹¤.

### 3ï¸âƒ£ `Xception`: Entry Flow, Middle FlowÃ—8, Exit Flow ëŒ€ì‘
`Xception` í´ë˜ìŠ¤ëŠ” ë…¼ë¬¸ Fig. 5ì˜ í° íë¦„ì„ ì½”ë“œë¡œ ì¡°ë¦½í•œë‹¤.

#### 3.1 Stem: ë‘ ê°œì˜ ì´ˆê¸° Convolution
ì´ˆê¸° ë¶€ë¶„ì€ `ConvBNReLU2d`ë¥¼ ì‚¬ìš©í•´ 3Ã—3 convolution ë‘ ë²ˆìœ¼ë¡œ ì±„ë„ì„ 32, 64ë¡œ ëŠ˜ë¦°ë‹¤.

```python
self.conv1 = nn.ConvBNReLU2d(
    3, 32, kernel_size=3, stride=2, padding=0, conv_bias=False
)
self.conv2 = nn.ConvBNReLU2d(32, 64, kernel_size=3, conv_bias=False)
```

ì—¬ê¸°ì„œ `conv1`ì€ stride 2ë¡œ í•´ìƒë„ë¥¼ ì¤„ì´ê³ , `conv2`ëŠ” stride 1ë¡œ ì¶”ê°€ ë³€í™˜ì„ ìˆ˜í–‰í•œë‹¤.

#### 3.2 Entry Flow: ì±„ë„ í™•ì¥ê³¼ ë‹¤ìš´ìƒ˜í”Œë§ì„ í¬í•¨í•œ 3ê°œ ë¸”ë¡
entry flowëŠ” `_Block` 3ê°œë¡œ êµ¬ì„±ëœë‹¤.

```python
self.block1 = _Block(64, 128, reps=2, stride=2, start_with_relu=False)
self.block2 = _Block(128, 256, reps=2, stride=2)
self.block3 = _Block(256, 728, reps=2, stride=2)
```

ê° ë¸”ë¡ì€ stride 2ë¡œ ë‹¤ìš´ìƒ˜í”Œë§ì„ ìˆ˜í–‰í•˜ë©´ì„œ ì±„ë„ì„ 128, 256, 728ë¡œ í™•ì¥í•œë‹¤. `block1`ì´ `start_with_relu=False`ì¸ ê²ƒì€ ë¸”ë¡ ê²½ê³„ì—ì„œ activation ë°°ì¹˜ë¥¼ ì¡°ì •í•˜ê¸° ìœ„í•œ ì„¤ì •ìœ¼ë¡œ ì½ì„ ìˆ˜ ìˆë‹¤.

#### 3.3 Middle Flow: ë™ì¼ ì±„ë„(728)ì—ì„œ ë°˜ë³µë˜ëŠ” 8ê°œ ë¸”ë¡
middle flowëŠ” ë™ì¼í•œ `_Block(728, 728, reps=3)`ë¥¼ 8íšŒ ë°˜ë³µí•œ `nn.Sequential`ì´ë‹¤.

```python
self.mid_blocks = nn.Sequential(*[_Block(728, 728, reps=3) for _ in range(8)])
```

ë…¼ë¬¸ì´ middle flow ë°˜ë³µì„ ê°•ì¡°í•˜ëŠ” ì§€ì ê³¼ ë™ì¼í•˜ê²Œ, êµ¬í˜„ë„ ë°˜ë³µ êµ¬ì¡°ê°€ ë§¤ìš° ëª…í™•í•˜ë‹¤.

#### 3.4 Exit Flow: ì±„ë„ í™•ì¥(1024â†’1536â†’2048)ê³¼ ë¶„ë¥˜ Head
exit flowì˜ ì²« ë‹¨ê³„ëŠ” `end_block`ì´ë‹¤.

```python
self.end_block = _Block(728, 1024, reps=2, stride=2, grow_first=False)
```

ì´í›„ ë‘ ê°œì˜ depthwise separable convì™€ BN, ReLUë¥¼ ì ìš©í•´ ì±„ë„ì„ 1536, 2048ë¡œ í™•ì¥í•œë‹¤.

```python
self.conv3 = nn.DepthSeparableConv2d(1024, 1536, kernel_size=3, padding=1)
self.bn3 = nn.BatchNorm2d(1536)

self.conv4 = nn.DepthSeparableConv2d(1536, 2048, kernel_size=3, padding=1)
self.bn4 = nn.BatchNorm2d(2048)
```

ë§ˆì§€ë§‰ì€ global average poolingê³¼ linear classifierë‹¤.

```python
self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
self.fc = nn.Linear(2048, num_classes)
```

#### 3.5 Forward ì „ì²´ íë¦„
forwardëŠ” ë…¼ë¬¸ ë„ì‹ì˜ ìˆœì„œë¥¼ ê·¸ëŒ€ë¡œ ë”°ë¥¸ë‹¤.

```python
def forward(self, x: Tensor) -> Tensor:
    x = self.conv1(x)
    x = self.conv2(x)

    x = self.block3(self.block2(self.block1(x)))
    x = self.mid_blocks(x)
    x = self.end_block(x)

    x = self.relu(self.bn3(self.conv3(x)))
    x = self.relu(self.bn4(self.conv4(x)))

    x = self.avgpool(x)
    x = x.reshape(x.shape[0], -1)
    x = self.fc(x)
    return x
```

ì—¬ê¸°ì„œ ì¤‘ìš”í•œ êµ¬í˜„ í¬ì¸íŠ¸ëŠ” ë‹¤ìŒì´ë‹¤.

1. Entry flowëŠ” `block1 â†’ block2 â†’ block3`ë¡œ ì§ë ¬ ì ìš©ëœë‹¤.  
2. Middle flowëŠ” `self.mid_blocks`ë¡œ ë°˜ë³µì´ ì¶”ìƒí™”ëœë‹¤.  
3. Exit flowëŠ” `end_block` ì´í›„ separable conv + BN + ReLU 2íšŒë¡œ ë§ˆë¬´ë¦¬ëœë‹¤.  
4. ë¶„ë¥˜ headëŠ” `AdaptiveAvgPool2d((1,1)) â†’ flatten â†’ Linear`ì´ë‹¤.  

ì¦‰, ë…¼ë¬¸ì´ ê°•ì¡°í•œ Xceptionì˜ ì¥ì  ì¤‘ í•˜ë‚˜ì¸ êµ¬ì¡°ì  ë‹¨ìˆœì„±ì´ ì½”ë“œ êµ¬ì¡°ì—ì„œë„ ê·¸ëŒ€ë¡œ ë‚˜íƒ€ë‚œë‹¤.

### 4ï¸âƒ£ ëª¨ë¸ ë“±ë¡ í•¨ìˆ˜ `xception`
LucidëŠ” `@register_model` ë°ì½”ë ˆì´í„°ë¡œ ëª¨ë¸ì„ ë“±ë¡í•œë‹¤.

```python
@register_model
def xception(num_classes: int = 1000, **kwargs) -> Xception:
    return Xception(num_classes, **kwargs)
```

ì´ í•¨ìˆ˜ëŠ” `Xception` ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•´ ë°˜í™˜í•˜ë©°, ì™¸ë¶€ì—ì„œëŠ” registryë¥¼ í†µí•´ `xception` ì´ë¦„ìœ¼ë¡œ ëª¨ë¸ì„ ìƒì„±í•  ìˆ˜ ìˆë‹¤.

---

## âœ… ì •ë¦¬
Xceptionì€ Inception ëª¨ë“ˆì„ ì—°ì‚° ë¶„í•´ì˜ ê´€ì ì—ì„œ ì¬í•´ì„í•˜ê³ , ê·¸ ë¶„í•´ë¥¼ ê·¹ë‹¨ìœ¼ë¡œ ë°€ì–´ë¶™ì¸ depthwise separable convolutionì„ Inception ëª¨ë“ˆì˜ ëŒ€ì²´ë¬¼ë¡œ ì œì•ˆí•œë‹¤. ì•„í‚¤í…ì²˜ëŠ” entry/middle/exit flowì˜ ì„ í˜• ìŠ¤íƒ í˜•íƒœë¡œ ì •ë¦¬ë˜ë©°, ëª¨ë“ˆ ë‹¨ìœ„ residual connectionì„ ê´‘ë²”ìœ„í•˜ê²Œ ì‚¬ìš©í•´ í•™ìŠµì„ ì•ˆì •í™”í•œë‹¤. ì‹¤í—˜ì—ì„œëŠ” Inception V3ì™€ ìœ ì‚¬í•œ íŒŒë¼ë¯¸í„° ìˆ˜ì—ì„œ ImageNetì—ì„œ ì†Œí­ì˜ ê°œì„ ì„, JFTì—ì„œ ë” í° ê°œì„ ì„ ë³´ê³ í•´ íŒŒë¼ë¯¸í„° íš¨ìœ¨ ì£¼ì¥ì„ ê°•í™”í•œë‹¤. ë˜í•œ residual connectionê³¼ ì¤‘ê°„ activationì˜ íš¨ê³¼ë¥¼ ë³„ë„ ì‹¤í—˜ìœ¼ë¡œ ë¶„í•´í•´ ì„¤ê³„ ì„ íƒì˜ í•„ìš”ì„±ì„ ë…¼ì¦í•œë‹¤.

- í•µì‹¬ ê´€ì : Inceptionâ€“Depthwise Separable ì—°ì†ì²´(ì´ì‚° ìŠ¤í™íŠ¸ëŸ¼)  
- í•µì‹¬ ì—°ì‚°: Depthwise Separable Convolution(Depthwise + Pointwise)  
- í•µì‹¬ ê²°ê³¼: ImageNet ì†Œí­ ê°œì„ , JFT í° ê°œì„ (Table 1, Table 2)  
- êµ¬í˜„ ëŒ€ì‘: `DepthSeparableConv2d` + `_Block` residual ëª¨ë“ˆ + `Xception`ì˜ Entry/Middle/Exit ì¡°ë¦½  

#### ğŸ“„ ì¶œì²˜
Chollet, FranÃ§ois. "Xception: Deep Learning With Depthwise Separable Convolutions." *2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, 2017, arXiv:1610.02357. https://arxiv.org/abs/1610.02357.
